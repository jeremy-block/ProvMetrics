{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "iDM05XHRsRiR"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "import itertools\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdoXthImwj6H"
      },
      "source": [
        "# Category Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCfoFFFZzTAF"
      },
      "source": [
        "# Action Categories\n",
        "'Add note'-\n",
        "'Connection'\n",
        "'Create Note'-\n",
        "'Doc_open'-\n",
        "'Draging'-\n",
        "'Highlight'-\n",
        "'Mouse_hover'-\n",
        "'Reading'-\n",
        "'Search'-\n",
        "'Think_aloud'-\n",
        "'Topic_change'-\n",
        "\n",
        "## Exploratory\n",
        "### Data Exploration\n",
        "- Search\n",
        "- Reading\n",
        "- Doc_open\n",
        "- Topic_change\n",
        "### Visual Exploration\n",
        "- Draging\n",
        "- Mouse_hover\n",
        "## Insight Action\n",
        "- Think_aloud\n",
        "- Highlight\n",
        "- Create Note\n",
        "- Add note\n",
        "- Connection\n",
        "## Theorizing (Data to Visual)\n",
        "## Discovering (Data to Insight)\n",
        "## Auditing (Insight to Data or anything to topic change)\n",
        "## Organizing (Insight to Visual)\n",
        "## Recognizing (Visual to Insight)\n",
        "## Tracking (Visual to Data)\n",
        "## Meta (Discarded)\n",
        "- So far none, but add logic for easy reconfig later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Update below to accommodate different action word encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'User ID': 4, 'Step': 0, 'Timestamp': 1605015240000, 'Event Type': 'switch', 'Visualization': 'instructions', 'Document Name': None, 'Document Type': None, 'Document Source': None, 'Keywords': None, 'People': None, 'Sender': None, 'Receiver': None, 'Start Time': None, 'End Time': None, 'Origin Latitude': None, 'Origin Longitude': None, 'Origin City': None, 'Origin Country': None, 'Destination Latitude': None, 'Destination Longitude': None, 'Destination City': None, 'Destination Country': None, 'Reasoning Type': None, 'Reasoning Text': None, 'Suspect': None, 'Hypothesis': None, 'Readable': 'Switched to: instructions', 'Query String': ''}\n",
            "{'save', 'revisit', 'search', 'discover', 'read', 'switch', 'assign'}\n"
          ]
        }
      ],
      "source": [
        "# # Edit the following to sample the interactions in a particular dataset. \n",
        "# # Choose a interaction log (in JSON), and specify which key you'd like a list of available options for.\n",
        "interaction_log_sample = \"../data/Dataset_5/interactions/user_4.json\"\n",
        "event_type_key = \"Event Type\"\n",
        "\n",
        "# Load JSON data\n",
        "with open(interaction_log_sample, 'r') as file:\n",
        "    data = json.load(file)\n",
        "print(data[0])\n",
        "\n",
        "# Extract Unique Event Types\n",
        "event_types = set(event[event_type_key] for event in data)\n",
        "\n",
        "# Print the list of event types\n",
        "print(event_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "dhK7SMERwx6q"
      },
      "outputs": [],
      "source": [
        "# Parameterizable Category Definitions\n",
        "\n",
        "\"\"\"\n",
        "TODO: Add a sys.args parser to populate below variables\n",
        "\n",
        "DataExplore = []\n",
        "Visual = []\n",
        "Insight = []\n",
        "Theorizing = []\n",
        "Discover = []\n",
        "Audit = []\n",
        "Organize = []\n",
        "Recognize = []\n",
        "Track = []\n",
        "\"\"\"\n",
        "case = 5\n",
        "\n",
        "if case == 1:\n",
        "    # For Datasets 1-3\n",
        "    DataExplore = [\"Search\", \"Reading\", \"Doc_open\", \"Topic_change\"]\n",
        "    Visual = [\"Draging\", \"Mouse_hover\"]\n",
        "    Insight = [\"Think_aloud\", \"Highlight\", \"Create Note\", \"Add note\", \"Connection\"]\n",
        "    # Theorizing = []\n",
        "    # Discover = []\n",
        "    # Audit = []\n",
        "    # Organize = []\n",
        "    # Recognize = []\n",
        "    # Track = []\n",
        "elif case == 4:\n",
        "    # For Dataset 4\n",
        "    DataExplore = [\n",
        "        \"expand\",\n",
        "        \"read\",\n",
        "        \"reads\",\n",
        "        \"find\",\n",
        "        \"listening\",\n",
        "        \"playAudioFileInNewWindow\",\n",
        "        \"query\",\n",
        "        \"collapse\",\n",
        "        \"selectedDateOnHistogram\",\n",
        "    ]\n",
        "    Visual = [\n",
        "        \"tabs to questions\",\n",
        "        \"query results\",\n",
        "        \"show\",\n",
        "        \"loadDocumentList\",\n",
        "        \"custom\",\n",
        "        \"tabs to abreviations\",\n",
        "        \"initiate\",\n",
        "        \"tabs to bundle\",\n",
        "        \"tabs to CAP\",\n",
        "        \"getdocuments\",\n",
        "        \"initialized\",\n",
        "        \"tabs to supplementary\",\n",
        "        \"tabs to bundles\",\n",
        "    ]\n",
        "    Insight = [\n",
        "        \"removeFromDocumentBucket\",\n",
        "        \"edit_document_bucket\",\n",
        "        \"answers question\",\n",
        "        \"answer\",\n",
        "        \"addToDocumentBucket\",\n",
        "        \"answers confidence\",\n",
        "        \"think_aloud\",\n",
        "        \"dispositionUpdated\",\n",
        "        \"noteUpdated\",\n",
        "        \"createDocumentBucket\",\n",
        "    ]\n",
        "    # Theorizing = []\n",
        "    # Discover = []\n",
        "    # Audit = []\n",
        "    # Organize = []\n",
        "    # Recognize = []\n",
        "    # Track = []\n",
        "elif case == 5:\n",
        "    # For Datasets 5\n",
        "    DataExplore = [\"discover\", \"search\", \"read\", \"revisit\"]\n",
        "    Visual = [\"switch\"]\n",
        "    Insight = [\"save\", \"assign\"]\n",
        "    # Theorizing = []\n",
        "    # Discover = []\n",
        "    # Audit = []\n",
        "    # Organize = []\n",
        "    # Recognize = []\n",
        "    # Track = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ7Zv6ZnSYec"
      },
      "source": [
        "# Data Clean-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note for the line - if 'Type' in t:\n",
        "Likely need pre-data file clean-up or make explicit what the column name is for other data sets. For instance, the UK dataset has multiple column headers that contain \"Type\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "QL2naFIkrZc9"
      },
      "outputs": [],
      "source": [
        "def json_to_csv(directory, filepath):\n",
        "    with open(os.path.join(directory, filepath)) as json_file:\n",
        "        data = json.load(json_file)\n",
        "\n",
        "    interaction_data = data\n",
        "\n",
        "    data_file = open('temp_markov/'+filepath + '.csv', 'w')\n",
        "\n",
        "    csv_writer = csv.writer(data_file)\n",
        "\n",
        "    count = 0\n",
        "    for interaction in interaction_data:\n",
        "        if count == 0:\n",
        "            header = interaction.keys()\n",
        "            for t in header:\n",
        "                if 'Type' in t: #for UK dataset, likely need to change to specifically \"Event Type\" since there are multiple header columns with \"Type\" in the name\n",
        "                    t = event_type_key\n",
        "            csv_writer.writerow(header)\n",
        "            count += 1\n",
        "\n",
        "        csv_writer.writerow(interaction.values())\n",
        "\n",
        "    data_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OELagBubSa08"
      },
      "source": [
        "# Probabilities and Markov Model Calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "YI8RBVZ_DdDn"
      },
      "outputs": [],
      "source": [
        "def ratioMaker(activities):\n",
        "  stuff, activity_counts = np.unique(activities, return_counts=True)\n",
        "  return [i/len(activities) for i in activity_counts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "ll0kSfJYu0xC"
      },
      "outputs": [],
      "source": [
        "def state_collecting(csv_file):\n",
        "    data = open(csv_file, 'r')\n",
        "\n",
        "    csv_data = csv.DictReader(data)\n",
        "    # data_lines = list(csv_data)\n",
        "\n",
        "    activities = []\n",
        "\n",
        "    for row in csv_data: #data_lines[1:]:\n",
        "        activities.append(row[event_type_key])\n",
        "\n",
        "    activity_list = (map(str, activities))\n",
        "\n",
        "    ratios = ratioMaker(activities)\n",
        "    # print(\"ratios: \", ratios)\n",
        "    # print(\"Ratio average: \", np.average(ratios))\n",
        "\n",
        "    activities = list(zip(activities, activities[1:])) #Create list of single-step interaction transitions\n",
        "\n",
        "    state_types = np.unique(activities)\n",
        "    state_count = len(state_types)\n",
        "\n",
        "    # List of all single-step transition types possible given all interaction labels, including A->B, B->A and A->A transitions\n",
        "    transition_types = np.unique(list(itertools.product(state_types, state_types)), axis=0)\n",
        "\n",
        "    #state_transitions are the list of unique single-step transitions present in the dataset, transition_counts is the number of times each state_transition appears in the log\n",
        "    state_transitions, transition_counts = np.unique(activities, return_counts=True, axis=0)\n",
        "\n",
        "    return activities, state_types, state_count, transition_types, state_transitions, transition_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "1QQaJuv5u7L4"
      },
      "outputs": [],
      "source": [
        "def transition_matrix(transition_counts, transition_types, state_count, state_transitions, activities):\n",
        "    n = state_count #number of states\n",
        "\n",
        "    m = np.zeros((n,n))#[0]*n for _ in range(n))\n",
        "    labels = np.empty((n,n), dtype=object)\n",
        "\n",
        "    y = 0\n",
        "    for x in state_transitions:\n",
        "      for i in range(state_count):\n",
        "        for j in range(state_count):\n",
        "            labels[i,j] = transition_types[i*state_count+j]\n",
        "            if all(x == transition_types[i*state_count+j]):\n",
        "                m[i][j] = transition_counts[y]\n",
        "      y += 1\n",
        "\n",
        "    # for row in m: print(' '.join('{0:.3f}'.format(x) for x in row))\n",
        "\n",
        "    #now convert to probabilities:\n",
        "    for row in m:\n",
        "        s = sum(row)\n",
        "        if s > 0:\n",
        "            row[:] = [f/s for f in row]\n",
        "    return m, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Note for the next few blocks:\n",
        "In the Visual Start State sections, there are spots that are hard-coded to individual event names, this is because of the weirdness we had with Topic_change in datasets 1-3. This can likely be modularized for the other sets, and feel free to change the categorizing rules to eliminate this scenario if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "relLRZPHxb-5"
      },
      "outputs": [],
      "source": [
        "def mask_labels(labels):\n",
        "    categorized = np.empty(labels.shape, dtype=object)\n",
        "    for i in range(labels.shape[0]):\n",
        "        for j in range(labels.shape[1]):\n",
        "            x = labels[i][j]\n",
        "            # Data Start State\n",
        "            if any(x[0] == data for data in DataExplore):\n",
        "                # Data to Data\n",
        "                if any(x[1] == data for data in DataExplore):\n",
        "                    categorized[i][j] = 'DataExploration'\n",
        "                # Data to Visual\n",
        "                elif any(x[1] == vis for vis in Visual):\n",
        "                    categorized[i][j] = 'Theorizing'\n",
        "                # Data to Insight\n",
        "                elif any(x[1] == idea for idea in Insight):\n",
        "                    categorized[i][j] = 'Discovering'\n",
        "\n",
        "            # Visual Start State\n",
        "            elif any(x[0] == vis for vis in Visual):\n",
        "                # Visual to Visual\n",
        "                if any(x[1] == vis for vis in Visual):\n",
        "                    categorized[i][j] = 'VisualExploration'\n",
        "                # Visual to Data\n",
        "                elif x[1] == 'Search' or x[1] == 'Reading' or x[1] == 'Doc_open': # Hard-coded part\n",
        "                    categorized[i][j] = 'Tracking'\n",
        "                # Visual to Insight\n",
        "                elif any(x[1] == idea for idea in Insight):\n",
        "                    categorized[i][j] = 'Recognizing'\n",
        "                # Visual to New Topic\n",
        "                elif x[1] == 'Topic_change': # Hard-coded part\n",
        "                    categorized[i][j] = 'Auditing'\n",
        "\n",
        "            # Insight Start State\n",
        "            elif any(x[0] == idea for idea in Insight):\n",
        "                # Insight to Insight\n",
        "                if any(x[1] == idea for idea in Insight):\n",
        "                    categorized[i][j] = 'InsightAction'\n",
        "                # Insight to Data\n",
        "                elif any(x[1] == data for data in DataExplore):\n",
        "                    categorized[i][j] = 'Auditing'\n",
        "                # Insight to Visual\n",
        "                elif any(x[1] == vis for vis in Visual):\n",
        "                    categorized[i][j] = 'Organizing'\n",
        "    return categorized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "LjRlqjKzBvFc"
      },
      "outputs": [],
      "source": [
        "def categorize_actions_row_average(activities, transition_counts, m):\n",
        "    categorized = []\n",
        "\n",
        "    \"\"\"\n",
        "    Threshold: 20%\n",
        "            Data[0] | Visual[1] | Insight[2] | Theorize (D-V)[3] | Discovery (D-I)[4] | New Idea (I-D or TC)[5] | Organize (I-V)[6] | Pattern (V-I)[7] | Trail (V-D)[8]\n",
        "    Usual\n",
        "    Unusual\n",
        "    \"\"\"\n",
        "    expectedness = np.zeros(shape=(9, 2))\n",
        "\n",
        "    for x in activities:\n",
        "        # Data Start State\n",
        "        if any(x[0] == data for data in DataExplore):\n",
        "            # Data to Data\n",
        "            if any(x[1] == data for data in DataExplore):\n",
        "                categorized.append(\"DataExploration\")\n",
        "            # Data to Visual\n",
        "            elif any(x[1] == vis for vis in Visual):\n",
        "                categorized.append(\"Theorizing\")\n",
        "            # Data to Insight\n",
        "            elif any(x[1] == idea for idea in Insight):\n",
        "                categorized.append(\"Discovering\")\n",
        "\n",
        "        # Visual Start State\n",
        "        elif any(x[0] == vis for vis in Visual):\n",
        "            # Visual to Visual\n",
        "            if any(x[1] == vis for vis in Visual):\n",
        "                categorized.append(\"VisualExploration\")\n",
        "            # Visual to Data\n",
        "            # elif x[1] == 'Search' or x[1] == 'Reading' or x[1] == 'Doc_open': # Hard-coded part\n",
        "            elif any(x[1] == data for data in DataExplore):\n",
        "                categorized.append(\"Tracking\")\n",
        "            # Visual to Insight\n",
        "            elif any(x[1] == idea for idea in Insight):\n",
        "                categorized.append(\"Recognizing\")\n",
        "            # # Visual to New Topic\n",
        "            # elif x[1] == \"Topic_change\":  # Hard-coded part\n",
        "            #     categorized.append(\"Auditing\")\n",
        "\n",
        "        # Insight Start State\n",
        "        elif any(x[0] == idea for idea in Insight):\n",
        "            # Insight to Insight\n",
        "            if any(x[1] == idea for idea in Insight):\n",
        "                categorized.append(\"InsightAction\")\n",
        "            # Insight to Data\n",
        "            elif any(x[1] == data for data in DataExplore):\n",
        "                categorized.append(\"Auditing\")\n",
        "            # Insight to Visual\n",
        "            elif any(x[1] == vis for vis in Visual):\n",
        "                categorized.append(\"Organizing\")\n",
        "\n",
        "        # Count expectedness\n",
        "        for i in range(state_count):\n",
        "            for j in range(state_count):\n",
        "                if all(x == transition_types[i * state_count + j]) and m[i][\n",
        "                    j\n",
        "                ] >= np.average([x for x in m[i] if x != 0]):\n",
        "                    if categorized[-1] == \"DataExploration\":\n",
        "                        expectedness[0][0] += 1\n",
        "                    elif categorized[-1] == \"VisualExploration\":\n",
        "                        expectedness[1][0] += 1\n",
        "                    elif categorized[-1] == \"InsightAction\":\n",
        "                        expectedness[2][0] += 1\n",
        "                    elif categorized[-1] == \"Theorizing\":\n",
        "                        expectedness[3][0] += 1\n",
        "                    elif categorized[-1] == \"Discovering\":\n",
        "                        expectedness[4][0] += 1\n",
        "                    elif categorized[-1] == \"Auditing\":\n",
        "                        expectedness[5][0] += 1\n",
        "                    elif categorized[-1] == \"Organizing\":\n",
        "                        expectedness[6][0] += 1\n",
        "                    elif categorized[-1] == \"Recognizing\":\n",
        "                        expectedness[7][0] += 1\n",
        "                    elif categorized[-1] == \"Tracking\":\n",
        "                        expectedness[8][0] += 1\n",
        "                elif all(x == transition_types[i * state_count + j]) and m[i][\n",
        "                    j\n",
        "                ] < np.average([x for x in m[i] if x != 0]):\n",
        "                    if categorized[-1] == \"DataExploration\":\n",
        "                        expectedness[0][1] += 1\n",
        "                    elif categorized[-1] == \"VisualExploration\":\n",
        "                        expectedness[1][1] += 1\n",
        "                    elif categorized[-1] == \"InsightAction\":\n",
        "                        expectedness[2][1] += 1\n",
        "                    elif categorized[-1] == \"Theorizing\":\n",
        "                        expectedness[3][1] += 1\n",
        "                    elif categorized[-1] == \"Discovering\":\n",
        "                        expectedness[4][1] += 1\n",
        "                    elif categorized[-1] == \"Auditing\":\n",
        "                        expectedness[5][1] += 1\n",
        "                    elif categorized[-1] == \"Organizing\":\n",
        "                        expectedness[6][1] += 1\n",
        "                    elif categorized[-1] == \"Recognizing\":\n",
        "                        expectedness[7][1] += 1\n",
        "                    elif categorized[-1] == \"Tracking\":\n",
        "                        expectedness[8][1] += 1\n",
        "\n",
        "    return expectedness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "zxX6MirMA-Is"
      },
      "outputs": [],
      "source": [
        "def interaction_category_counts(state_transitions):\n",
        "    interaction_counts = np.zeros(shape=(9,1))\n",
        "\n",
        "    h = 0\n",
        "    #Topic change only considered for data to data and insight to data\n",
        "    for x in state_transitions:\n",
        "        if any(x[0] == data for data in DataExplore):\n",
        "            if any(x[1] == data for data in DataExplore):\n",
        "                interaction_counts[0] += transition_counts[h]\n",
        "            elif any(x[1] == vis for vis in Visual):\n",
        "                interaction_counts[3] += transition_counts[h]\n",
        "            elif any(x[1] == idea for idea in Insight):\n",
        "                interaction_counts[4] += transition_counts[h]\n",
        "\n",
        "        elif any(x[0] == vis for vis in Visual):\n",
        "            if any(x[1] == vis for vis in Visual):\n",
        "                interaction_counts[1] += transition_counts[h]\n",
        "            elif x[1] == 'Search' or x[1] == 'Reading' or x[1] == 'Doc_open': # Hard-coded part\n",
        "                interaction_counts[8] += transition_counts[h]\n",
        "            elif any(x[1] == idea for idea in Insight):\n",
        "                interaction_counts[7] += transition_counts[h]\n",
        "            elif x[1] == 'Topic_change': # Hard-coded part\n",
        "                interaction_counts[5] += transition_counts[h]\n",
        "\n",
        "        elif any(x[0] == idea for idea in Insight):\n",
        "            if any(x[1] == idea for idea in Insight):\n",
        "                interaction_counts[2] += transition_counts[h]\n",
        "            elif any(x[1] == data for data in DataExplore):\n",
        "                interaction_counts[5] += transition_counts[h]\n",
        "            elif any(x[1] == vis for vis in Visual):\n",
        "                interaction_counts[6] += transition_counts[h]\n",
        "        h += 1\n",
        "\n",
        "    return interaction_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkijuLqYRnoO"
      },
      "source": [
        "# Run on DataSets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "gF4tDgAAR_6k"
      },
      "outputs": [],
      "source": [
        "directory = \"./../data/Dataset_5/interactions/\"\n",
        "event_type_key = event_type_key\n",
        "csv_file = \"markov_5.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU_Vy03oRxu9"
      },
      "source": [
        "## Perform on all participants in directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VoQ6RZsu85B",
        "outputId": "342ff513-bb68-45aa-fcdd-305e240335b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Panda_P2_interactions.json\n",
            "\n",
            "\n",
            "\n",
            "counts\n",
            " [[  37.]\n",
            " [  10.]\n",
            " [1150.]\n",
            " [  14.]\n",
            " [  41.]\n",
            " [  42.]\n",
            " [  48.]\n",
            " [  50.]\n",
            " [   0.]]\n",
            "usual, unusual split\n",
            " [[  22.   15.]\n",
            " [   2.    8.]\n",
            " [1122.   28.]\n",
            " [  12.    2.]\n",
            " [  39.    2.]\n",
            " [   0.   42.]\n",
            " [   0.   48.]\n",
            " [  43.    7.]\n",
            " [   7.    6.]]\n",
            "Warning: Division by zero or invalid value detected. Setting affected values to zero.\n",
            "final matrix\n",
            " [[0.59459459 0.40540541]\n",
            " [0.2        0.8       ]\n",
            " [0.97565217 0.02434783]\n",
            " [0.85714286 0.14285714]\n",
            " [0.95121951 0.04878049]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.86       0.14      ]\n",
            " [7.         6.        ]\n",
            " [0.89519024 0.11342426]]\n",
            "[[0.59459459 0.2        0.97565217 0.85714286 0.95121951 0.\n",
            "  0.         0.86       7.         0.89519024]\n",
            " [0.40540541 0.8        0.02434783 0.14285714 0.04878049 1.\n",
            "  1.         0.14       6.         0.11342426]]\n",
            "[0.59459459 0.2        0.97565217 0.85714286 0.95121951 0.\n",
            " 0.         0.86       7.         0.89519024 0.40540541 0.8\n",
            " 0.02434783 0.14285714 0.04878049 1.         1.         0.14\n",
            " 6.         0.11342426]\n",
            "Panda_P3_interactions.json\n",
            "\n",
            "\n",
            "\n",
            "counts\n",
            " [[  9.]\n",
            " [  0.]\n",
            " [261.]\n",
            " [ 10.]\n",
            " [ 16.]\n",
            " [ 24.]\n",
            " [  6.]\n",
            " [ 14.]\n",
            " [  0.]]\n",
            "usual, unusual split\n",
            " [[  6.   3.]\n",
            " [  0.   0.]\n",
            " [261.   0.]\n",
            " [ 10.   0.]\n",
            " [ 16.   0.]\n",
            " [  0.  24.]\n",
            " [  0.   6.]\n",
            " [ 14.   0.]\n",
            " [  1.   1.]]\n",
            "Warning: Division by zero or invalid value detected. Setting affected values to zero.\n",
            "final matrix\n",
            " [[0.66666667 0.33333333]\n",
            " [0.         0.        ]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [1.         1.        ]\n",
            " [0.9005848  0.0994152 ]]\n",
            "[[0.66666667 0.         1.         1.         1.         0.\n",
            "  0.         1.         1.         0.9005848 ]\n",
            " [0.33333333 0.         0.         0.         0.         1.\n",
            "  1.         0.         1.         0.0994152 ]]\n",
            "[0.66666667 0.         1.         1.         1.         0.\n",
            " 0.         1.         1.         0.9005848  0.33333333 0.\n",
            " 0.         0.         0.         1.         1.         0.\n",
            " 1.         0.0994152 ]\n",
            "[['Panda_P2_interactions.json', 37.0, 10.0, 1150.0, 14.0, 41.0, 42.0, 48.0, 50.0, 1.0, 0.5945945945945946, 0.2, 0.9756521739130435, 0.8571428571428571, 0.9512195121951219, 0.0, 0.0, 0.86, 7.0, 0.8951902368987796, 0.40540540540540543, 0.8, 0.02434782608695652, 0.14285714285714285, 0.04878048780487805, 1.0, 1.0, 0.14, 6.0, 0.11342426417803302], ['Panda_P3_interactions.json', 9.0, 1.0, 261.0, 10.0, 16.0, 24.0, 6.0, 14.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.9005847953216374, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.09941520467836257]]\n"
          ]
        }
      ],
      "source": [
        "FullSetProbabilities = []\n",
        "for filename in sorted(os.listdir(directory)):\n",
        "    print(filename + \"\\n\")\n",
        "    json_to_csv(directory, filename)\n",
        "    activities, state_types, state_count, transition_types, state_transitions, transition_counts = state_collecting('temp_markov/'+filename+'.csv')\n",
        "\n",
        "    m, labels = transition_matrix(transition_counts, transition_types, state_count, state_transitions, activities)\n",
        "    print(\"\\n\")\n",
        "    # for row in m: print(' '.join('{0:.3f}'.format(x) for x in row))\n",
        "    # for row in labels: print(' '.join('{}'.format(x) for x in row))\n",
        "\n",
        "    label_masked = mask_labels(labels)\n",
        "    # for row in label_masked: print(' '.join('{}'.format(x) for x in row))\n",
        "    expected2 = categorize_actions_row_average(activities, transition_counts, m)\n",
        "    inters = interaction_category_counts(state_transitions)\n",
        "\n",
        "\n",
        "    print(\"counts\\n\",inters)\n",
        "    print(\"usual, unusual split\\n\",expected2)\n",
        "\n",
        "    # Add a small epsilon value to avoid division by zero\n",
        "    epsilon = 1e-10\n",
        "\n",
        "    # Check for division by zero or invalid values\n",
        "    mask = np.isclose(inters, 0, atol=epsilon)\n",
        "    if np.any(mask):\n",
        "        print(\"Warning: Division by zero or invalid value detected. Setting affected values to zero.\")\n",
        "        inters[mask] = 1  # Set to 1 to avoid division by zero\n",
        "\n",
        "    percentages = expected2 / inters\n",
        "\n",
        "    # Check for division by zero in percentage_Totals calculation\n",
        "    if sum(inters) == 0:\n",
        "        print(\"Error: Total count is zero. Unable to calculate percentage_Totals.\")\n",
        "    else:\n",
        "        percentage_Totals = (sum(expected2) / sum(inters))\n",
        "        percentages.resize((10, 2))\n",
        "        percentages[-1] = percentage_Totals\n",
        "\n",
        "    print(\"final matrix\\n\", percentages)\n",
        "\n",
        "    percentages = percentages.transpose()\n",
        "    print(percentages)\n",
        "    print(percentages.flatten())\n",
        "\n",
        "    ParticipantData = []\n",
        "    ParticipantData.append(filename)\n",
        "    for x in inters.flatten():\n",
        "        ParticipantData.append(x)\n",
        "    for y in percentages.flatten():\n",
        "        ParticipantData.append(y)\n",
        "    FullSetProbabilities.append(ParticipantData)\n",
        "\n",
        "    data_file = open('temp_markov/probabilities' + filename + '.csv', 'w')\n",
        "\n",
        "    csv_writer = csv.writer(data_file)\n",
        "\n",
        "    headings = [\"DataExploration\", \"VisualExploration\", \"InsightAction\", \"Theorizing\", \"Discovering\", \"Auditing\", \"Organizing\", \"Recognizing\", \"Tracking\", \"Total\"]\n",
        "    count = 0\n",
        "    for i in percentages:\n",
        "      if count == 0:\n",
        "        header = [\"DataExploration\", \"VisualExploration\", \"InsightAction\", \"Theorizing\", \"Discovering\", \"Auditing\", \"Organizing\", \"Recognizing\", \"Tracking\", \"Total\"]\n",
        "        csv_writer.writerow(header)\n",
        "        count += 1\n",
        "      csv_writer.writerow(i)\n",
        "\n",
        "    data_file.close()\n",
        "\n",
        "print(FullSetProbabilities)\n",
        "data_file = open(csv_file, 'w')\n",
        "\n",
        "csv_writer = csv.writer(data_file)\n",
        "\n",
        "headings = [\"DataExploration\", \"VisualExploration\", \"InsightAction\", \"Theorizing\", \"Discovering\", \"Auditing\", \"Organizing\", \"Recognizing\", \"Tracking\", \"Total\"]\n",
        "count = 0\n",
        "for i in FullSetProbabilities:\n",
        "    if count == 0:\n",
        "        header = [\"FileName\", \"DataExplorationCounts\", \"VisualExplorationCounts\", \"InsightActionCounts\", \"TheorizingCounts\", \"DiscoveringCounts\", \"AuditingCounts\", \"OrganizingCounts\", \"RecognizingCounts\", \"TrackingCounts\",\n",
        "                  \"DataExploringUsual\", \"VisualExploringUsual\", \"InsightActionUsual\", \"TheorizingUsual\", \"DiscoveringUsual\", \"AuditingUsual\", \"OrganizingUsual\", \"RecognizingUsual\", \"TrackingUsual\", \"TotalUsual\",\n",
        "                  \"DataExploringUnusual\", \"VisualExploringUnusual\", \"InsightActionUnusual\", \"TheorizingUnusual\", \"DiscoveringUnusual\", \"AuditingUnusual\", \"OrganizingUnusual\", \"RecognizingUnusual\", \"TrackingUnusual\", \"TotalUnusual\"]\n",
        "        csv_writer.writerow(header)\n",
        "        count += 1\n",
        "    csv_writer.writerow(i)\n",
        "\n",
        "data_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y21MSx5SR4L8"
      },
      "source": [
        "## Run on single participant for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVr2jDyUA-v9",
        "outputId": "c30baf64-a76f-4807-9c19-609cb426cd66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_0.json\n",
            "\n",
            "\n",
            "\n",
            "counts\n",
            " [[12.]\n",
            " [82.]\n",
            " [ 0.]\n",
            " [30.]\n",
            " [ 2.]\n",
            " [ 0.]\n",
            " [ 5.]\n",
            " [ 4.]\n",
            " [ 0.]]\n",
            "usual, unusual split\n",
            " [[11.  1.]\n",
            " [82.  0.]\n",
            " [ 0.  0.]\n",
            " [27.  3.]\n",
            " [ 0.  2.]\n",
            " [ 0.  0.]\n",
            " [ 5.  0.]\n",
            " [ 0.  4.]\n",
            " [ 0. 32.]]\n",
            "Warning: Division by zero or invalid value detected. Setting affected values to zero.\n",
            "final matrix\n",
            " [[ 0.91666667  0.08333333]\n",
            " [ 1.          0.        ]\n",
            " [ 0.          0.        ]\n",
            " [ 0.9         0.1       ]\n",
            " [ 0.          1.        ]\n",
            " [ 0.          0.        ]\n",
            " [ 1.          0.        ]\n",
            " [ 0.          1.        ]\n",
            " [ 0.         32.        ]\n",
            " [ 0.9057971   0.30434783]]\n"
          ]
        }
      ],
      "source": [
        "directory = './../data/Dataset_5/interactions/'\n",
        "filename = 'user_0.json'\n",
        "\n",
        "print(filename + \"\\n\")\n",
        "json_to_csv(directory, filename)\n",
        "activities, state_types, state_count, transition_types, state_transitions, transition_counts = state_collecting(\"temp_markov/\"+filename+'.csv')\n",
        "\n",
        "m, labels = transition_matrix(transition_counts, transition_types, state_count, state_transitions, activities)\n",
        "print(\"\\n\")\n",
        "# for row in m: print(' '.join('{0:.3f}'.format(x) for x in row))\n",
        "# for row in labels: print(' '.join('{}'.format(x) for x in row))\n",
        "\n",
        "label_masked = mask_labels(labels)\n",
        "# for row in label_masked: print(' '.join('{}'.format(x) for x in row))\n",
        "expected2 = categorize_actions_row_average(activities, transition_counts, m)\n",
        "inters = interaction_category_counts(state_transitions)\n",
        "\n",
        "print(\"counts\\n\",inters)\n",
        "print(\"usual, unusual split\\n\",expected2)\n",
        "\n",
        "# Add a small epsilon value to avoid division by zero\n",
        "epsilon = 1e-10\n",
        "\n",
        "# Check for division by zero or invalid values\n",
        "mask = np.isclose(inters, 0, atol=epsilon)\n",
        "if np.any(mask):\n",
        "    print(\"Warning: Division by zero or invalid value detected. Setting affected values to zero.\")\n",
        "    inters[mask] = 1  # Set to 1 to avoid division by zero\n",
        "\n",
        "percentages = expected2 / inters\n",
        "\n",
        "# Check for division by zero in percentage_Totals calculation\n",
        "if sum(inters) == 0:\n",
        "    print(\"Error: Total count is zero. Unable to calculate percentage_Totals.\")\n",
        "else:\n",
        "    percentage_Totals = (sum(expected2) / sum(inters))\n",
        "    percentages.resize((10, 2))\n",
        "    percentages[-1] = percentage_Totals\n",
        "\n",
        "print(\"final matrix\\n\", percentages)\n",
        "\n",
        "percentages = percentages.transpose()\n",
        "\n",
        "ParticipantData = []\n",
        "for x in inters.flatten():\n",
        "    ParticipantData.append(x)\n",
        "for y in percentages.flatten():\n",
        "    ParticipantData.append(y)\n",
        "\n",
        "prob_file = open('temp_markov/probabilities' + filename + '.csv', 'w')\n",
        "csv_writer = csv.writer(prob_file)\n",
        "\n",
        "header = [\"DataExplorationCounts\", \"VisualExplorationCounts\", \"InsightActionCounts\", \"TheorizingCounts\", \"DiscoveringCounts\", \"AuditingCounts\", \"OrganizingCounts\", \"RecognizingCounts\", \"TrackingCounts\",\n",
        "            \"DataExploringUsual\", \"VisualExploringUsual\", \"InsightActionUsual\", \"TheorizingUsual\", \"DiscoveringUsual\", \"AuditingUsual\", \"OrganizingUsual\", \"RecognizingUsual\", \"TrackingUsual\", \"TotalUsual\",\n",
        "            \"DataExploringUnusual\", \"VisualExploringUnusual\", \"InsightActionUnusual\", \"TheorizingUnusual\", \"DiscoveringUnusual\", \"AuditingUnusual\", \"OrganizingUnusual\", \"RecognizingUnusual\", \"TrackingUnusual\", \"TotalUnusual\"]\n",
        "csv_writer.writerow(header)\n",
        "\n",
        "csv_writer.writerow(ParticipantData)\n",
        "\n",
        "prob_file.close()\n",
        "\n",
        "data_file = open('temp_markov/MarkovValues' + filename + '.csv', 'w')\n",
        "\n",
        "csv_writer = csv.writer(data_file)\n",
        "\n",
        "count = 0\n",
        "for i in m:\n",
        "  if count == 0:\n",
        "    header = state_types.flatten()\n",
        "    csv_writer.writerow(header)\n",
        "    count += 1\n",
        "\n",
        "  csv_writer.writerow(i)\n",
        "\n",
        "data_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yFO54-ySIl0"
      },
      "source": [
        "# Visualization Attempts (Ignore these, as they don't work)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EaqfC6SORss"
      },
      "outputs": [],
      "source": [
        "### Attempt to Visualize States ###\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.collections import PatchCollection\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "class Node():\n",
        "\n",
        "    def __init__(\n",
        "        self, center, radius, label,\n",
        "        facecolor='#2693de', edgecolor='#e6e6e6',\n",
        "        ring_facecolor='#a3a3a3', ring_edgecolor='#a3a3a3'\n",
        "        ):\n",
        "        \"\"\"\n",
        "        Initializes a Markov Chain Node(for drawing purposes)\n",
        "        Inputs:\n",
        "            - center : Node (x,y) center\n",
        "            - radius : Node radius\n",
        "            - label  : Node label\n",
        "        \"\"\"\n",
        "        self.center = center\n",
        "        self.radius = radius\n",
        "        self.label  = label\n",
        "\n",
        "        # For convinience: x, y coordinates of the center\n",
        "        self.x = center[0]\n",
        "        self.y = center[1]\n",
        "\n",
        "        # Drawing config\n",
        "        self.node_facecolor = facecolor\n",
        "        self.node_edgecolor = edgecolor\n",
        "\n",
        "        self.ring_facecolor = ring_facecolor\n",
        "        self.ring_edgecolor = ring_edgecolor\n",
        "        self.ring_width = 0.03\n",
        "\n",
        "        self.text_args = {\n",
        "            'ha': 'center',\n",
        "            'va': 'center',\n",
        "            'fontsize': 16\n",
        "        }\n",
        "\n",
        "\n",
        "    def add_circle(self, ax):\n",
        "        \"\"\"\n",
        "        Add the annotated circle for the node\n",
        "        \"\"\"\n",
        "        circle = mpatches.Circle(self.center, self.radius)\n",
        "        p = PatchCollection(\n",
        "            [circle],\n",
        "            edgecolor = self.node_edgecolor,\n",
        "            facecolor = self.node_facecolor\n",
        "        )\n",
        "        ax.add_collection(p)\n",
        "        ax.annotate(\n",
        "            self.label,\n",
        "            xy = self.center,\n",
        "            color = '#ffffff',\n",
        "            **self.text_args\n",
        "        )\n",
        "\n",
        "\n",
        "    def add_self_loop(self, ax, prob=None, direction='up'):\n",
        "        \"\"\"\n",
        "        Draws a self loop\n",
        "        \"\"\"\n",
        "        if direction == 'up':\n",
        "            start = -30\n",
        "            angle = 180\n",
        "            ring_x = self.x\n",
        "            ring_y = self.y + self.radius\n",
        "            prob_y = self.y + 1.3*self.radius\n",
        "            x_cent = ring_x - self.radius + (self.ring_width/2)\n",
        "            y_cent = ring_y - 0.15\n",
        "        else:\n",
        "            start = -210\n",
        "            angle = 0\n",
        "            ring_x = self.x\n",
        "            ring_y = self.y - self.radius\n",
        "            prob_y = self.y - 1.4*self.radius\n",
        "            x_cent = ring_x + self.radius - (self.ring_width/2)\n",
        "            y_cent = ring_y + 0.15\n",
        "\n",
        "        # Add the ring\n",
        "        ring = mpatches.Wedge(\n",
        "            (ring_x, ring_y),\n",
        "            self.radius,\n",
        "            start,\n",
        "            angle,\n",
        "            width = self.ring_width\n",
        "        )\n",
        "        # Add the triangle (arrow)\n",
        "        offset = 0.2\n",
        "        left   = [x_cent - offset, ring_y]\n",
        "        right  = [x_cent + offset, ring_y]\n",
        "        bottom = [(left[0]+right[0])/2., y_cent]\n",
        "        arrow  = plt.Polygon([left, right, bottom, left])\n",
        "\n",
        "        p = PatchCollection(\n",
        "            [ring, arrow],\n",
        "            edgecolor = self.ring_edgecolor,\n",
        "            facecolor = self.ring_facecolor\n",
        "        )\n",
        "        ax.add_collection(p)\n",
        "\n",
        "        # Probability to add?\n",
        "        if prob:\n",
        "            ax.annotate(str(prob), xy=(self.x, prob_y), color='#000000', **self.text_args)\n",
        "\n",
        "\n",
        "class MarkovChain:\n",
        "\n",
        "    def __init__(self, M, labels):\n",
        "        \"\"\"\n",
        "        Initializes a Markov Chain (for drawing purposes)\n",
        "        Inputs:\n",
        "            - M         Transition Matrix\n",
        "            - labels    State Labels\n",
        "        \"\"\"\n",
        "\n",
        "        if M.shape[0] < 2:\n",
        "            raise Exception(\"There should be at least 2 states\")\n",
        "        # if M.shape[0] > 4:\n",
        "        #     raise Exception(\"Only works with 4 states max for now\")\n",
        "        if M.shape[0] != M.shape[1]:\n",
        "            raise Exception(\"Transition matrix should be square\")\n",
        "        if M.shape[0] != len(labels):\n",
        "            raise Exception(\"There should be as many labels as states\")\n",
        "\n",
        "        self.M = M\n",
        "        self.n_states = M.shape[0]\n",
        "        self.labels = labels\n",
        "\n",
        "        # Colors\n",
        "        self.arrow_facecolor = '#a3a3a3'\n",
        "        self.arrow_edgecolor = '#a3a3a3'\n",
        "\n",
        "        self.node_facecolor = '#2693de'\n",
        "        self.node_edgecolor = '#e6e6e6'\n",
        "\n",
        "        # Drawing config\n",
        "        self.node_radius = 0.5\n",
        "        self.arrow_width = 0.03\n",
        "        self.arrow_head_width = 0.20\n",
        "        self.text_args = {\n",
        "            'ha': 'center',\n",
        "            'va': 'center',\n",
        "            'fontsize': 16\n",
        "        }\n",
        "\n",
        "        # Build the network\n",
        "        self.build_network()\n",
        "\n",
        "\n",
        "    def set_node_centers(self):\n",
        "        \"\"\"\n",
        "        Positions the node centers given the number of states\n",
        "        \"\"\"\n",
        "        # Node positions\n",
        "        self.node_centers = []\n",
        "\n",
        "        if self.n_states == 2:\n",
        "            self.figsize = (10, 4)\n",
        "            self.xlim = (-5, 5)\n",
        "            self.ylim = (-2, 2)\n",
        "            self.node_centers = [[-4,0], [4,0]]\n",
        "        elif self.n_states == 3:\n",
        "            self.figsize = (10, 6)\n",
        "            self.xlim = (-5, 5)\n",
        "            self.ylim = (-3, 3)\n",
        "            self.node_centers = [[-3,-2], [3,-2], [-3,2]]\n",
        "        elif self.n_states == 4:\n",
        "            self.figsize = (8, 8)\n",
        "            self.xlim = (-5, 5)\n",
        "            self.ylim = (-5, 5)\n",
        "            self.node_centers = [[-4,4], [4,4], [4,-4], [-4,-4]]\n",
        "        else:\n",
        "            self.figsize = (self.n_states * 2, self.n_states * 2)\n",
        "            self.xlim = (-20,20)\n",
        "            self.ylim = (-20,20)\n",
        "            self.node_centers = [[-10, 15], [0, 15], [10, 15], [-10, 5], [0, 5], [10, 5], [-10, -5], [0, -5], [10, -5], [-10, -15], [0, -15]]\n",
        "\n",
        "\n",
        "    def build_network(self):\n",
        "        \"\"\"\n",
        "        Loops through the matrix, add the nodes\n",
        "        \"\"\"\n",
        "        # Position the node centers\n",
        "        self.set_node_centers()\n",
        "\n",
        "        # Set the nodes\n",
        "        self.nodes = []\n",
        "        for i in range(self.n_states):\n",
        "            node = Node(\n",
        "                self.node_centers[i],\n",
        "                self.node_radius,\n",
        "                self.labels[i]\n",
        "            )\n",
        "            self.nodes.append(node)\n",
        "\n",
        "\n",
        "    def add_arrow(self, ax, node1, node2, prob=None):\n",
        "        \"\"\"\n",
        "        Add a directed arrow between two nodes\n",
        "        \"\"\"\n",
        "        # x,y start of the arrow\n",
        "        x_start = node1.x + np.sign(node2.x-node1.x) * node1.radius\n",
        "        y_start = node1.y + np.sign(node2.y-node1.y) * node1.radius\n",
        "\n",
        "        # arrow length\n",
        "        dx = abs(node1.x - node2.x) - 2.5* node1.radius\n",
        "        dy = abs(node1.y - node2.y) - 2.5* node1.radius\n",
        "\n",
        "        # we don't want xoffset and yoffset to both be non-nul\n",
        "        yoffset = 0.4 * self.node_radius * np.sign(node2.x-node1.x)\n",
        "        if yoffset == 0:\n",
        "            xoffset = 0.4 * self.node_radius * np.sign(node2.y-node1.y)\n",
        "        else:\n",
        "            xoffset = 0\n",
        "\n",
        "        arrow = mpatches.FancyArrow(\n",
        "            x_start + xoffset,\n",
        "            y_start + yoffset,\n",
        "            dx * np.sign(node2.x-node1.x),\n",
        "            dy * np.sign(node2.y-node1.y),\n",
        "            width = self.arrow_width,\n",
        "            head_width = self.arrow_head_width\n",
        "        )\n",
        "        p = PatchCollection(\n",
        "            [arrow],\n",
        "            edgecolor = self.arrow_edgecolor,\n",
        "            facecolor = self.arrow_facecolor\n",
        "        )\n",
        "        ax.add_collection(p)\n",
        "\n",
        "        # Probability to add?\n",
        "        x_prob = x_start + xoffset + 0.2*dx*np.sign(node2.x-node1.x)\n",
        "        y_prob = y_start + yoffset + 0.2*dy*np.sign(node2.y-node1.y)\n",
        "        if prob:\n",
        "            ax.annotate(str(prob), xy=(x_prob, y_prob), color='#000000', **self.text_args)\n",
        "\n",
        "\n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Draw the Markov Chain\n",
        "        \"\"\"\n",
        "        fig, ax = plt.subplots(figsize=self.figsize)\n",
        "\n",
        "        # Set the axis limits\n",
        "        plt.xlim(self.xlim)\n",
        "        plt.ylim(self.ylim)\n",
        "\n",
        "        # Draw the nodes\n",
        "        for node in self.nodes:\n",
        "            node.add_circle(ax)\n",
        "\n",
        "        # Add the transitions\n",
        "        for i in range(self.M.shape[0]):\n",
        "            for j in range(self.M.shape[1]):\n",
        "                # self loops\n",
        "                if i == j:\n",
        "                    # Loop direction\n",
        "                    if self.nodes[i].y >= 0:\n",
        "                        self.nodes[i].add_self_loop(ax, prob = M[i,j], direction='up')\n",
        "                    else:\n",
        "                        self.nodes[i].add_self_loop(ax, prob = M[i,j], direction='down')\n",
        "                # directed arrows\n",
        "                elif M[i,j] > 0:\n",
        "                    self.add_arrow(ax, self.nodes[i], self.nodes[j], prob = M[i,j])\n",
        "\n",
        "        plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "tlGKtTm0RvZ-",
        "outputId": "b6469e95-aa40-4858-d773-0e84e03cfe0e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-51bf46b3c793>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMarkovChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
          ]
        }
      ],
      "source": [
        "mc = MarkovChain(m, state_types)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "dU_Vy03oRxu9",
        "9yFO54-ySIl0"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
