{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iDM05XHRsRiR"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "import itertools\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdoXthImwj6H"
      },
      "source": [
        "# Category Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCfoFFFZzTAF"
      },
      "source": [
        "# Action Categories\n",
        "'Add note'-\n",
        "'Connection'\n",
        "'Create Note'-\n",
        "'Doc_open'-\n",
        "'Draging'-\n",
        "'Highlight'-\n",
        "'Mouse_hover'-\n",
        "'Reading'-\n",
        "'Search'-\n",
        "'Think_aloud'-\n",
        "'Topic_change'-\n",
        "\n",
        "## Exploratory\n",
        "### Data Exploration\n",
        "- Search\n",
        "- Reading\n",
        "- Doc_open\n",
        "- Topic_change\n",
        "### Visual Exploration\n",
        "- Draging\n",
        "- Mouse_hover\n",
        "## Insight Action\n",
        "- Think_aloud\n",
        "- Highlight\n",
        "- Create Note\n",
        "- Add note\n",
        "- Connection\n",
        "## Theorizing (Data to Visual)\n",
        "## Discovering (Data to Insight)\n",
        "## Auditing (Insight to Data or anything to topic change)\n",
        "## Organizing (Insight to Visual)\n",
        "## Recognizing (Visual to Insight)\n",
        "## Tracking (Visual to Data)\n",
        "## Meta (Discarded)\n",
        "- So far none, but add logic for easy reconfig later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Update below to accommodate different action word encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dhK7SMERwx6q"
      },
      "outputs": [],
      "source": [
        "# Parameterizable Category Definitions\n",
        "\n",
        "'''\n",
        "TODO: Add a sys.args parser to populate below variables\n",
        "\n",
        "DataExplore = []\n",
        "Visual = []\n",
        "Insight = []\n",
        "Theorizing = []\n",
        "Discover = []\n",
        "Audit = []\n",
        "Organize = []\n",
        "Recognize = []\n",
        "Track = []\n",
        "'''\n",
        "\n",
        "# For Datasets 1-3\n",
        "DataExplore = ['Search', 'Reading', 'Doc_open', 'Topic_change']\n",
        "Visual = ['Draging', 'Mouse_hover']\n",
        "Insight = ['Think_aloud', 'Highlight', 'Create Note', 'Add note', 'Connection']\n",
        "# Theorizing = []\n",
        "# Discover = []\n",
        "# Audit = []\n",
        "# Organize = []\n",
        "# Recognize = []\n",
        "# Track = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ7Zv6ZnSYec"
      },
      "source": [
        "# Data Clean-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note for the line - if 'Type' in t:\n",
        "Likely need pre-data file clean-up or make explicit what the column name is for other data sets. For instance, the UK dataset has multiple column headers that contain \"Type\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QL2naFIkrZc9"
      },
      "outputs": [],
      "source": [
        "def json_to_csv(directory, filepath):\n",
        "    with open(os.path.join(directory, filepath)) as json_file:\n",
        "        data = json.load(json_file)\n",
        "\n",
        "    interaction_data = data\n",
        "\n",
        "    data_file = open('temp_markov/'+filepath + '.csv', 'w')\n",
        "\n",
        "    csv_writer = csv.writer(data_file)\n",
        "\n",
        "    count = 0\n",
        "    for interaction in interaction_data:\n",
        "        if count == 0:\n",
        "            header = interaction.keys()\n",
        "            for t in header:\n",
        "                if 'Type' in t: #for UK dataset, likely need to change to specifically \"Event Type\" since there are multiple header columns with \"Type\" in the name\n",
        "                    t = 'interactionType'\n",
        "            csv_writer.writerow(header)\n",
        "            count += 1\n",
        "\n",
        "        csv_writer.writerow(interaction.values())\n",
        "\n",
        "    data_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OELagBubSa08"
      },
      "source": [
        "# Probabilities and Markov Model Calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YI8RBVZ_DdDn"
      },
      "outputs": [],
      "source": [
        "def ratioMaker(activities):\n",
        "  stuff, activity_counts = np.unique(activities, return_counts=True)\n",
        "  return [i/len(activities) for i in activity_counts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ll0kSfJYu0xC"
      },
      "outputs": [],
      "source": [
        "def state_collecting(csv_file):\n",
        "    data = open(csv_file, 'r')\n",
        "\n",
        "    csv_data = csv.DictReader(data)\n",
        "    # data_lines = list(csv_data)\n",
        "\n",
        "    activities = []\n",
        "\n",
        "    for row in csv_data: #data_lines[1:]:\n",
        "        activities.append(row['interactionType'])\n",
        "\n",
        "    activity_list = (map(str, activities))\n",
        "\n",
        "    ratios = ratioMaker(activities)\n",
        "    # print(\"ratios: \", ratios)\n",
        "    # print(\"Ratio average: \", np.average(ratios))\n",
        "\n",
        "    activities = list(zip(activities, activities[1:])) #Create list of single-step interaction transitions\n",
        "\n",
        "    state_types = np.unique(activities)\n",
        "    state_count = len(state_types)\n",
        "\n",
        "    # List of all single-step transition types possible given all interaction labels, including A->B, B->A and A->A transitions\n",
        "    transition_types = np.unique(list(itertools.product(state_types, state_types)), axis=0)\n",
        "\n",
        "    #state_transitions are the list of unique single-step transitions present in the dataset, transition_counts is the number of times each state_transition appears in the log\n",
        "    state_transitions, transition_counts = np.unique(activities, return_counts=True, axis=0)\n",
        "\n",
        "    return activities, state_types, state_count, transition_types, state_transitions, transition_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1QQaJuv5u7L4"
      },
      "outputs": [],
      "source": [
        "def transition_matrix(transition_counts, transition_types, state_count, state_transitions, activities):\n",
        "    n = state_count #number of states\n",
        "\n",
        "    m = np.zeros((n,n))#[0]*n for _ in range(n))\n",
        "    labels = np.empty((n,n), dtype=object)\n",
        "\n",
        "    y = 0\n",
        "    for x in state_transitions:\n",
        "      for i in range(state_count):\n",
        "        for j in range(state_count):\n",
        "            labels[i,j] = transition_types[i*state_count+j]\n",
        "            if all(x == transition_types[i*state_count+j]):\n",
        "                m[i][j] = transition_counts[y]\n",
        "      y += 1\n",
        "\n",
        "    # for row in m: print(' '.join('{0:.3f}'.format(x) for x in row))\n",
        "\n",
        "    #now convert to probabilities:\n",
        "    for row in m:\n",
        "        s = sum(row)\n",
        "        if s > 0:\n",
        "            row[:] = [f/s for f in row]\n",
        "    return m, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Note for the next few blocks:\n",
        "In the Visual Start State sections, there are spots that are hard-coded to individual event names, this is because of the weirdness we had with Topic_change in datasets 1-3. This can likely be modularized for the other sets, and feel free to change the categorizing rules to eliminate this scenario if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "relLRZPHxb-5"
      },
      "outputs": [],
      "source": [
        "def mask_labels(labels):\n",
        "    categorized = np.empty(labels.shape, dtype=object)\n",
        "    for i in range(labels.shape[0]):\n",
        "        for j in range(labels.shape[1]):\n",
        "            x = labels[i][j]\n",
        "            # Data Start State\n",
        "            if any(x[0] == data for data in DataExplore):\n",
        "                # Data to Data\n",
        "                if any(x[1] == data for data in DataExplore):\n",
        "                    categorized[i][j] = 'DataExploration'\n",
        "                # Data to Visual\n",
        "                elif any(x[1] == vis for vis in Visual):\n",
        "                    categorized[i][j] = 'Theorizing'\n",
        "                # Data to Insight\n",
        "                elif any(x[1] == idea for idea in Insight):\n",
        "                    categorized[i][j] = 'Discovering'\n",
        "\n",
        "            # Visual Start State\n",
        "            elif any(x[0] == vis for vis in Visual):\n",
        "                # Visual to Visual\n",
        "                if any(x[1] == vis for vis in Visual):\n",
        "                    categorized[i][j] = 'VisualExploration'\n",
        "                # Visual to Data\n",
        "                elif x[1] == 'Search' or x[1] == 'Reading' or x[1] == 'Doc_open': # Hard-coded part\n",
        "                    categorized[i][j] = 'Tracking'\n",
        "                # Visual to Insight\n",
        "                elif any(x[1] == idea for idea in Insight):\n",
        "                    categorized[i][j] = 'Recognizing'\n",
        "                # Visual to New Topic\n",
        "                elif x[1] == 'Topic_change': # Hard-coded part\n",
        "                    categorized[i][j] = 'Auditing'\n",
        "\n",
        "            # Insight Start State\n",
        "            elif any(x[0] == idea for idea in Insight):\n",
        "                # Insight to Insight\n",
        "                if any(x[1] == idea for idea in Insight):\n",
        "                    categorized[i][j] = 'InsightAction'\n",
        "                # Insight to Data\n",
        "                elif any(x[1] == data for data in DataExplore):\n",
        "                    categorized[i][j] = 'Auditing'\n",
        "                # Insight to Visual\n",
        "                elif any(x[1] == vis for vis in Visual):\n",
        "                    categorized[i][j] = 'Organizing'\n",
        "    return categorized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LjRlqjKzBvFc"
      },
      "outputs": [],
      "source": [
        "def categorize_actions_row_average(activities, transition_counts, m):\n",
        "    categorized = []\n",
        "\n",
        "    '''\n",
        "    Threshold: 20%\n",
        "            Data[0] | Visual[1] | Insight[2] | Theorize (D-V)[3] | Discovery (D-I)[4] | New Idea (I-D or TC)[5] | Organize (I-V)[6] | Pattern (V-I)[7] | Trail (V-D)[8]\n",
        "    Usual\n",
        "    Unusual\n",
        "    '''\n",
        "    expectedness = np.zeros(shape=(9,2))\n",
        "\n",
        "    for x in activities:\n",
        "        # Data Start State\n",
        "        if any(x[0] == data for data in DataExplore):\n",
        "            # Data to Data\n",
        "            if any(x[1] == data for data in DataExplore):\n",
        "                categorized.append('DataExploration')\n",
        "            # Data to Visual\n",
        "            elif any(x[1] == vis for vis in Visual):\n",
        "                categorized.append('Theorizing')\n",
        "            # Data to Insight\n",
        "            elif any(x[1] == idea for idea in Insight):\n",
        "                categorized.append('Discovering')\n",
        "\n",
        "        # Visual Start State\n",
        "        elif any(x[0] == vis for vis in Visual):\n",
        "            # Visual to Visual\n",
        "            if any(x[1] == vis for vis in Visual):\n",
        "                categorized.append('VisualExploration')\n",
        "            # Visual to Data\n",
        "            elif x[1] == 'Search' or x[1] == 'Reading' or x[1] == 'Doc_open': # Hard-coded part\n",
        "                categorized.append('Tracking')\n",
        "            # Visual to Insight\n",
        "            elif any(x[1] == idea for idea in Insight):\n",
        "                categorized.append('Recognizing')\n",
        "            # Visual to New Topic\n",
        "            elif x[1] == 'Topic_change': # Hard-coded part\n",
        "                categorized.append('Auditing')\n",
        "\n",
        "        # Insight Start State\n",
        "        elif any(x[0] == idea for idea in Insight):\n",
        "            # Insight to Insight\n",
        "            if any(x[1] == idea for idea in Insight):\n",
        "                categorized.append('InsightAction')\n",
        "            # Insight to Data\n",
        "            elif any(x[1] == data for data in DataExplore):\n",
        "                categorized.append('Auditing')\n",
        "            # Insight to Visual\n",
        "            elif any(x[1] == vis for vis in Visual):\n",
        "                categorized.append('Organizing')\n",
        "\n",
        "        # Count expectedness\n",
        "        for i in range(state_count):\n",
        "            for j in range(state_count):\n",
        "                if all(x == transition_types[i*state_count+j]) and m[i][j] >= np.average([x for x in m[i] if x != 0]):\n",
        "                    if categorized[-1] == 'DataExploration':\n",
        "                        expectedness[0][0] += 1\n",
        "                    elif categorized[-1] == 'VisualExploration':\n",
        "                        expectedness[1][0] += 1\n",
        "                    elif categorized[-1] == 'InsightAction':\n",
        "                        expectedness[2][0] += 1\n",
        "                    elif categorized[-1] == 'Theorizing':\n",
        "                        expectedness[3][0] += 1\n",
        "                    elif categorized[-1] == 'Discovering':\n",
        "                        expectedness[4][0] += 1\n",
        "                    elif categorized[-1] == 'Auditing':\n",
        "                        expectedness[5][0] += 1\n",
        "                    elif categorized[-1] == 'Organizing':\n",
        "                        expectedness[6][0] += 1\n",
        "                    elif categorized[-1] == 'Recognizing':\n",
        "                        expectedness[7][0] += 1\n",
        "                    elif categorized[-1] == 'Tracking':\n",
        "                        expectedness[8][0] += 1\n",
        "                elif all(x == transition_types[i*state_count+j]) and m[i][j] < np.average([x for x in m[i] if x != 0]):\n",
        "                    if categorized[-1] == 'DataExploration':\n",
        "                        expectedness[0][1] += 1\n",
        "                    elif categorized[-1] == 'VisualExploration':\n",
        "                        expectedness[1][1] += 1\n",
        "                    elif categorized[-1] == 'InsightAction':\n",
        "                        expectedness[2][1] += 1\n",
        "                    elif categorized[-1] == 'Theorizing':\n",
        "                        expectedness[3][1] += 1\n",
        "                    elif categorized[-1] == 'Discovering':\n",
        "                        expectedness[4][1] += 1\n",
        "                    elif categorized[-1] == 'Auditing':\n",
        "                        expectedness[5][1] += 1\n",
        "                    elif categorized[-1] == 'Organizing':\n",
        "                        expectedness[6][1] += 1\n",
        "                    elif categorized[-1] == 'Recognizing':\n",
        "                        expectedness[7][1] += 1\n",
        "                    elif categorized[-1] == 'Tracking':\n",
        "                        expectedness[8][1] += 1\n",
        "\n",
        "    return expectedness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zxX6MirMA-Is"
      },
      "outputs": [],
      "source": [
        "def interaction_category_counts(state_transitions):\n",
        "    interaction_counts = np.zeros(shape=(9,1))\n",
        "\n",
        "    h = 0\n",
        "    #Topic change only considered for data to data and insight to data\n",
        "    for x in state_transitions:\n",
        "        if any(x[0] == data for data in DataExplore):\n",
        "            if any(x[1] == data for data in DataExplore):\n",
        "                interaction_counts[0] += transition_counts[h]\n",
        "            elif any(x[1] == vis for vis in Visual):\n",
        "                interaction_counts[3] += transition_counts[h]\n",
        "            elif any(x[1] == idea for idea in Insight):\n",
        "                interaction_counts[4] += transition_counts[h]\n",
        "\n",
        "        elif any(x[0] == vis for vis in Visual):\n",
        "            if any(x[1] == vis for vis in Visual):\n",
        "                interaction_counts[1] += transition_counts[h]\n",
        "            elif x[1] == 'Search' or x[1] == 'Reading' or x[1] == 'Doc_open': # Hard-coded part\n",
        "                interaction_counts[8] += transition_counts[h]\n",
        "            elif any(x[1] == idea for idea in Insight):\n",
        "                interaction_counts[7] += transition_counts[h]\n",
        "            elif x[1] == 'Topic_change': # Hard-coded part\n",
        "                interaction_counts[5] += transition_counts[h]\n",
        "\n",
        "        elif any(x[0] == idea for idea in Insight):\n",
        "            if any(x[1] == idea for idea in Insight):\n",
        "                interaction_counts[2] += transition_counts[h]\n",
        "            elif any(x[1] == data for data in DataExplore):\n",
        "                interaction_counts[5] += transition_counts[h]\n",
        "            elif any(x[1] == vis for vis in Visual):\n",
        "                interaction_counts[6] += transition_counts[h]\n",
        "        h += 1\n",
        "\n",
        "    return interaction_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkijuLqYRnoO"
      },
      "source": [
        "# Run on DataSets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gF4tDgAAR_6k"
      },
      "outputs": [],
      "source": [
        "directory = \"./../data/Dataset_3/User Interactions/\"\n",
        "csv_file = \"markov_3.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU_Vy03oRxu9"
      },
      "source": [
        "## Perform on all participants in directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VoQ6RZsu85B",
        "outputId": "342ff513-bb68-45aa-fcdd-305e240335b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Disappearance_P1_InteractionsLogs.json\n",
            "\n",
            "\n",
            "\n",
            "[[168.]\n",
            " [113.]\n",
            " [ 61.]\n",
            " [102.]\n",
            " [ 54.]\n",
            " [ 59.]\n",
            " [ 38.]\n",
            " [ 38.]\n",
            " [ 98.]]\n",
            "[[144.  24.]\n",
            " [ 84.  29.]\n",
            " [ 53.   8.]\n",
            " [ 86.  16.]\n",
            " [ 32.  22.]\n",
            " [ 46.  13.]\n",
            " [ 23.  15.]\n",
            " [ 29.   9.]\n",
            " [ 65.  33.]]\n",
            "[[0.85714286 0.14285714]\n",
            " [0.74336283 0.25663717]\n",
            " [0.86885246 0.13114754]\n",
            " [0.84313725 0.15686275]\n",
            " [0.59259259 0.40740741]\n",
            " [0.77966102 0.22033898]\n",
            " [0.60526316 0.39473684]\n",
            " [0.76315789 0.23684211]\n",
            " [0.66326531 0.33673469]\n",
            " [0.76880985 0.23119015]]\n",
            "[[0.85714286 0.74336283 0.86885246 0.84313725 0.59259259 0.77966102\n",
            "  0.60526316 0.76315789 0.66326531 0.76880985]\n",
            " [0.14285714 0.25663717 0.13114754 0.15686275 0.40740741 0.22033898\n",
            "  0.39473684 0.23684211 0.33673469 0.23119015]]\n",
            "[0.85714286 0.74336283 0.86885246 0.84313725 0.59259259 0.77966102\n",
            " 0.60526316 0.76315789 0.66326531 0.76880985 0.14285714 0.25663717\n",
            " 0.13114754 0.15686275 0.40740741 0.22033898 0.39473684 0.23684211\n",
            " 0.33673469 0.23119015]\n",
            "Disappearance_P2_InteractionsLogs.json\n",
            "\n",
            "\n",
            "\n",
            "[[277.]\n",
            " [141.]\n",
            " [ 37.]\n",
            " [119.]\n",
            " [103.]\n",
            " [114.]\n",
            " [ 49.]\n",
            " [ 57.]\n",
            " [109.]]\n",
            "[[222.  55.]\n",
            " [141.   0.]\n",
            " [ 17.  20.]\n",
            " [ 72.  47.]\n",
            " [ 36.  67.]\n",
            " [104.  10.]\n",
            " [ 44.   5.]\n",
            " [ 26.  31.]\n",
            " [ 96.  13.]]\n",
            "[[0.80144404 0.19855596]\n",
            " [1.         0.        ]\n",
            " [0.45945946 0.54054054]\n",
            " [0.60504202 0.39495798]\n",
            " [0.34951456 0.65048544]\n",
            " [0.9122807  0.0877193 ]\n",
            " [0.89795918 0.10204082]\n",
            " [0.45614035 0.54385965]\n",
            " [0.88073394 0.11926606]\n",
            " [0.75347913 0.24652087]]\n",
            "[[0.80144404 1.         0.45945946 0.60504202 0.34951456 0.9122807\n",
            "  0.89795918 0.45614035 0.88073394 0.75347913]\n",
            " [0.19855596 0.         0.54054054 0.39495798 0.65048544 0.0877193\n",
            "  0.10204082 0.54385965 0.11926606 0.24652087]]\n",
            "[0.80144404 1.         0.45945946 0.60504202 0.34951456 0.9122807\n",
            " 0.89795918 0.45614035 0.88073394 0.75347913 0.19855596 0.\n",
            " 0.54054054 0.39495798 0.65048544 0.0877193  0.10204082 0.54385965\n",
            " 0.11926606 0.24652087]\n",
            "Disappearance_P3_InteractionsLogs.json\n",
            "\n",
            "\n",
            "\n",
            "[[430.]\n",
            " [ 67.]\n",
            " [ 34.]\n",
            " [121.]\n",
            " [ 75.]\n",
            " [ 74.]\n",
            " [ 41.]\n",
            " [ 39.]\n",
            " [123.]]\n",
            "[[350.  80.]\n",
            " [ 58.   9.]\n",
            " [ 29.   5.]\n",
            " [ 35.  86.]\n",
            " [ 10.  65.]\n",
            " [ 59.  15.]\n",
            " [ 36.   5.]\n",
            " [ 30.   9.]\n",
            " [108.  15.]]\n",
            "[[0.81395349 0.18604651]\n",
            " [0.86567164 0.13432836]\n",
            " [0.85294118 0.14705882]\n",
            " [0.2892562  0.7107438 ]\n",
            " [0.13333333 0.86666667]\n",
            " [0.7972973  0.2027027 ]\n",
            " [0.87804878 0.12195122]\n",
            " [0.76923077 0.23076923]\n",
            " [0.87804878 0.12195122]\n",
            " [0.71215139 0.28784861]]\n",
            "[[0.81395349 0.86567164 0.85294118 0.2892562  0.13333333 0.7972973\n",
            "  0.87804878 0.76923077 0.87804878 0.71215139]\n",
            " [0.18604651 0.13432836 0.14705882 0.7107438  0.86666667 0.2027027\n",
            "  0.12195122 0.23076923 0.12195122 0.28784861]]\n",
            "[0.81395349 0.86567164 0.85294118 0.2892562  0.13333333 0.7972973\n",
            " 0.87804878 0.76923077 0.87804878 0.71215139 0.18604651 0.13432836\n",
            " 0.14705882 0.7107438  0.86666667 0.2027027  0.12195122 0.23076923\n",
            " 0.12195122 0.28784861]\n",
            "Disappearance_P4_InteractionsLogs.json\n",
            "\n",
            "\n",
            "\n",
            "[[452.]\n",
            " [171.]\n",
            " [  9.]\n",
            " [139.]\n",
            " [ 49.]\n",
            " [ 46.]\n",
            " [ 16.]\n",
            " [ 13.]\n",
            " [143.]]\n",
            "[[402.  50.]\n",
            " [138.  33.]\n",
            " [  1.   8.]\n",
            " [ 75.  64.]\n",
            " [  0.  49.]\n",
            " [ 37.   9.]\n",
            " [ 12.   4.]\n",
            " [  0.  13.]\n",
            " [132.  11.]]\n",
            "[[0.88938053 0.11061947]\n",
            " [0.80701754 0.19298246]\n",
            " [0.11111111 0.88888889]\n",
            " [0.53956835 0.46043165]\n",
            " [0.         1.        ]\n",
            " [0.80434783 0.19565217]\n",
            " [0.75       0.25      ]\n",
            " [0.         1.        ]\n",
            " [0.92307692 0.07692308]\n",
            " [0.76782274 0.23217726]]\n",
            "[[0.88938053 0.80701754 0.11111111 0.53956835 0.         0.80434783\n",
            "  0.75       0.         0.92307692 0.76782274]\n",
            " [0.11061947 0.19298246 0.88888889 0.46043165 1.         0.19565217\n",
            "  0.25       1.         0.07692308 0.23217726]]\n",
            "[0.88938053 0.80701754 0.11111111 0.53956835 0.         0.80434783\n",
            " 0.75       0.         0.92307692 0.76782274 0.11061947 0.19298246\n",
            " 0.88888889 0.46043165 1.         0.19565217 0.25       1.\n",
            " 0.07692308 0.23217726]\n",
            "Disappearance_P5_InteractionsLogs.json\n",
            "\n",
            "\n",
            "\n",
            "[[183.]\n",
            " [181.]\n",
            " [  9.]\n",
            " [159.]\n",
            " [ 33.]\n",
            " [ 37.]\n",
            " [ 56.]\n",
            " [ 58.]\n",
            " [155.]]\n",
            "[[168.  15.]\n",
            " [181.   0.]\n",
            " [  5.   4.]\n",
            " [154.   5.]\n",
            " [  0.  33.]\n",
            " [ 27.  10.]\n",
            " [ 52.   4.]\n",
            " [ 46.  12.]\n",
            " [130.  25.]]\n",
            "[[0.91803279 0.08196721]\n",
            " [1.         0.        ]\n",
            " [0.55555556 0.44444444]\n",
            " [0.96855346 0.03144654]\n",
            " [0.         1.        ]\n",
            " [0.72972973 0.27027027]\n",
            " [0.92857143 0.07142857]\n",
            " [0.79310345 0.20689655]\n",
            " [0.83870968 0.16129032]\n",
            " [0.87600459 0.12399541]]\n",
            "[[0.91803279 1.         0.55555556 0.96855346 0.         0.72972973\n",
            "  0.92857143 0.79310345 0.83870968 0.87600459]\n",
            " [0.08196721 0.         0.44444444 0.03144654 1.         0.27027027\n",
            "  0.07142857 0.20689655 0.16129032 0.12399541]]\n",
            "[0.91803279 1.         0.55555556 0.96855346 0.         0.72972973\n",
            " 0.92857143 0.79310345 0.83870968 0.87600459 0.08196721 0.\n",
            " 0.44444444 0.03144654 1.         0.27027027 0.07142857 0.20689655\n",
            " 0.16129032 0.12399541]\n",
            "Disappearance_P6_InteractionsLogs.json\n",
            "\n",
            "\n",
            "\n",
            "[[624.]\n",
            " [201.]\n",
            " [ 23.]\n",
            " [241.]\n",
            " [103.]\n",
            " [107.]\n",
            " [ 49.]\n",
            " [ 47.]\n",
            " [238.]]\n",
            "[[537.  87.]\n",
            " [186.  15.]\n",
            " [ 11.  12.]\n",
            " [189.  52.]\n",
            " [  2. 101.]\n",
            " [ 89.  18.]\n",
            " [ 32.  17.]\n",
            " [  0.  47.]\n",
            " [228.  10.]]\n",
            "[[0.86057692 0.13942308]\n",
            " [0.92537313 0.07462687]\n",
            " [0.47826087 0.52173913]\n",
            " [0.78423237 0.21576763]\n",
            " [0.01941748 0.98058252]\n",
            " [0.8317757  0.1682243 ]\n",
            " [0.65306122 0.34693878]\n",
            " [0.         1.        ]\n",
            " [0.95798319 0.04201681]\n",
            " [0.78015922 0.21984078]]\n",
            "[[0.86057692 0.92537313 0.47826087 0.78423237 0.01941748 0.8317757\n",
            "  0.65306122 0.         0.95798319 0.78015922]\n",
            " [0.13942308 0.07462687 0.52173913 0.21576763 0.98058252 0.1682243\n",
            "  0.34693878 1.         0.04201681 0.21984078]]\n",
            "[0.86057692 0.92537313 0.47826087 0.78423237 0.01941748 0.8317757\n",
            " 0.65306122 0.         0.95798319 0.78015922 0.13942308 0.07462687\n",
            " 0.52173913 0.21576763 0.98058252 0.1682243  0.34693878 1.\n",
            " 0.04201681 0.21984078]\n",
            "Disappearance_P7_InteractionsLogs.json\n",
            "\n",
            "\n",
            "\n",
            "[[ 89.]\n",
            " [252.]\n",
            " [ 24.]\n",
            " [ 48.]\n",
            " [ 52.]\n",
            " [ 57.]\n",
            " [ 28.]\n",
            " [ 30.]\n",
            " [ 42.]]\n",
            "[[ 77.  12.]\n",
            " [252.   0.]\n",
            " [ 17.   7.]\n",
            " [ 32.  16.]\n",
            " [ 45.   7.]\n",
            " [ 40.  17.]\n",
            " [ 16.  12.]\n",
            " [ 21.   9.]\n",
            " [ 20.  22.]]\n",
            "[[0.86516854 0.13483146]\n",
            " [1.         0.        ]\n",
            " [0.70833333 0.29166667]\n",
            " [0.66666667 0.33333333]\n",
            " [0.86538462 0.13461538]\n",
            " [0.70175439 0.29824561]\n",
            " [0.57142857 0.42857143]\n",
            " [0.7        0.3       ]\n",
            " [0.47619048 0.52380952]\n",
            " [0.83601286 0.16398714]]\n",
            "[[0.86516854 1.         0.70833333 0.66666667 0.86538462 0.70175439\n",
            "  0.57142857 0.7        0.47619048 0.83601286]\n",
            " [0.13483146 0.         0.29166667 0.33333333 0.13461538 0.29824561\n",
            "  0.42857143 0.3        0.52380952 0.16398714]]\n",
            "[0.86516854 1.         0.70833333 0.66666667 0.86538462 0.70175439\n",
            " 0.57142857 0.7        0.47619048 0.83601286 0.13483146 0.\n",
            " 0.29166667 0.33333333 0.13461538 0.29824561 0.42857143 0.3\n",
            " 0.52380952 0.16398714]\n",
            "Disappearance_P8_InteractionsLogs.json\n",
            "\n",
            "\n",
            "\n",
            "[[446.]\n",
            " [342.]\n",
            " [ 11.]\n",
            " [210.]\n",
            " [ 72.]\n",
            " [ 46.]\n",
            " [ 54.]\n",
            " [ 28.]\n",
            " [236.]]\n",
            "[[401.  45.]\n",
            " [342.   0.]\n",
            " [  4.   7.]\n",
            " [143.  67.]\n",
            " [ 54.  18.]\n",
            " [ 16.  30.]\n",
            " [ 45.   9.]\n",
            " [  0.  28.]\n",
            " [213.  23.]]\n",
            "[[0.89910314 0.10089686]\n",
            " [1.         0.        ]\n",
            " [0.36363636 0.63636364]\n",
            " [0.68095238 0.31904762]\n",
            " [0.75       0.25      ]\n",
            " [0.34782609 0.65217391]\n",
            " [0.83333333 0.16666667]\n",
            " [0.         1.        ]\n",
            " [0.90254237 0.09745763]\n",
            " [0.84290657 0.15709343]]\n",
            "[[0.89910314 1.         0.36363636 0.68095238 0.75       0.34782609\n",
            "  0.83333333 0.         0.90254237 0.84290657]\n",
            " [0.10089686 0.         0.63636364 0.31904762 0.25       0.65217391\n",
            "  0.16666667 1.         0.09745763 0.15709343]]\n",
            "[0.89910314 1.         0.36363636 0.68095238 0.75       0.34782609\n",
            " 0.83333333 0.         0.90254237 0.84290657 0.10089686 0.\n",
            " 0.63636364 0.31904762 0.25       0.65217391 0.16666667 1.\n",
            " 0.09745763 0.15709343]\n",
            "[['Disappearance_P1_InteractionsLogs.json', 168.0, 113.0, 61.0, 102.0, 54.0, 59.0, 38.0, 38.0, 98.0, 0.8571428571428571, 0.7433628318584071, 0.8688524590163934, 0.8431372549019608, 0.5925925925925926, 0.7796610169491526, 0.6052631578947368, 0.7631578947368421, 0.6632653061224489, 0.7688098495212038, 0.14285714285714285, 0.25663716814159293, 0.13114754098360656, 0.1568627450980392, 0.4074074074074074, 0.22033898305084745, 0.39473684210526316, 0.23684210526315788, 0.336734693877551, 0.23119015047879618], ['Disappearance_P2_InteractionsLogs.json', 277.0, 141.0, 37.0, 119.0, 103.0, 114.0, 49.0, 57.0, 109.0, 0.8014440433212996, 1.0, 0.4594594594594595, 0.6050420168067226, 0.34951456310679613, 0.9122807017543859, 0.8979591836734694, 0.45614035087719296, 0.8807339449541285, 0.7534791252485089, 0.19855595667870035, 0.0, 0.5405405405405406, 0.3949579831932773, 0.6504854368932039, 0.08771929824561403, 0.10204081632653061, 0.543859649122807, 0.11926605504587157, 0.24652087475149106], ['Disappearance_P3_InteractionsLogs.json', 430.0, 67.0, 34.0, 121.0, 75.0, 74.0, 41.0, 39.0, 123.0, 0.813953488372093, 0.8656716417910447, 0.8529411764705882, 0.2892561983471074, 0.13333333333333333, 0.7972972972972973, 0.8780487804878049, 0.7692307692307693, 0.8780487804878049, 0.7121513944223108, 0.18604651162790697, 0.13432835820895522, 0.14705882352941177, 0.7107438016528925, 0.8666666666666667, 0.20270270270270271, 0.12195121951219512, 0.23076923076923078, 0.12195121951219512, 0.28784860557768926], ['Disappearance_P4_InteractionsLogs.json', 452.0, 171.0, 9.0, 139.0, 49.0, 46.0, 16.0, 13.0, 143.0, 0.8893805309734514, 0.8070175438596491, 0.1111111111111111, 0.539568345323741, 0.0, 0.8043478260869565, 0.75, 0.0, 0.9230769230769231, 0.7678227360308285, 0.11061946902654868, 0.19298245614035087, 0.8888888888888888, 0.460431654676259, 1.0, 0.1956521739130435, 0.25, 1.0, 0.07692307692307693, 0.2321772639691715], ['Disappearance_P5_InteractionsLogs.json', 183.0, 181.0, 9.0, 159.0, 33.0, 37.0, 56.0, 58.0, 155.0, 0.9180327868852459, 1.0, 0.5555555555555556, 0.9685534591194969, 0.0, 0.7297297297297297, 0.9285714285714286, 0.7931034482758621, 0.8387096774193549, 0.8760045924225028, 0.08196721311475409, 0.0, 0.4444444444444444, 0.031446540880503145, 1.0, 0.2702702702702703, 0.07142857142857142, 0.20689655172413793, 0.16129032258064516, 0.12399540757749714], ['Disappearance_P6_InteractionsLogs.json', 624.0, 201.0, 23.0, 241.0, 103.0, 107.0, 49.0, 47.0, 238.0, 0.8605769230769231, 0.9253731343283582, 0.4782608695652174, 0.7842323651452282, 0.019417475728155338, 0.8317757009345794, 0.6530612244897959, 0.0, 0.957983193277311, 0.7801592161665646, 0.13942307692307693, 0.07462686567164178, 0.5217391304347826, 0.2157676348547718, 0.9805825242718447, 0.16822429906542055, 0.3469387755102041, 1.0, 0.04201680672268908, 0.2198407838334354], ['Disappearance_P7_InteractionsLogs.json', 89.0, 252.0, 24.0, 48.0, 52.0, 57.0, 28.0, 30.0, 42.0, 0.8651685393258427, 1.0, 0.7083333333333334, 0.6666666666666666, 0.8653846153846154, 0.7017543859649122, 0.5714285714285714, 0.7, 0.47619047619047616, 0.8360128617363344, 0.1348314606741573, 0.0, 0.2916666666666667, 0.3333333333333333, 0.1346153846153846, 0.2982456140350877, 0.42857142857142855, 0.3, 0.5238095238095238, 0.1639871382636656], ['Disappearance_P8_InteractionsLogs.json', 446.0, 342.0, 11.0, 210.0, 72.0, 46.0, 54.0, 28.0, 236.0, 0.899103139013453, 1.0, 0.36363636363636365, 0.680952380952381, 0.75, 0.34782608695652173, 0.8333333333333334, 0.0, 0.902542372881356, 0.8429065743944637, 0.10089686098654709, 0.0, 0.6363636363636364, 0.319047619047619, 0.25, 0.6521739130434783, 0.16666666666666666, 1.0, 0.09745762711864407, 0.15709342560553632]]\n"
          ]
        }
      ],
      "source": [
        "FullSetProbabilities = []\n",
        "for filename in sorted(os.listdir(directory)):\n",
        "    print(filename + \"\\n\")\n",
        "    json_to_csv(directory, filename)\n",
        "    activities, state_types, state_count, transition_types, state_transitions, transition_counts = state_collecting('temp_markov/'+filename+'.csv')\n",
        "\n",
        "    m, labels = transition_matrix(transition_counts, transition_types, state_count, state_transitions, activities)\n",
        "    print(\"\\n\")\n",
        "    # for row in m: print(' '.join('{0:.3f}'.format(x) for x in row))\n",
        "    # for row in labels: print(' '.join('{}'.format(x) for x in row))\n",
        "\n",
        "    label_masked = mask_labels(labels)\n",
        "    # for row in label_masked: print(' '.join('{}'.format(x) for x in row))\n",
        "    expected2 = categorize_actions_row_average(activities, transition_counts, m)\n",
        "    inters = interaction_category_counts(state_transitions)\n",
        "\n",
        "    print(inters)\n",
        "    print(expected2)\n",
        "    percentages = expected2/inters\n",
        "    percentage_Totals = (sum(expected2)/sum(inters))\n",
        "    percentages.resize((10,2))\n",
        "    percentages[-1] = percentage_Totals\n",
        "    print(percentages)\n",
        "\n",
        "    percentages = percentages.transpose()\n",
        "    print(percentages)\n",
        "    print(percentages.flatten())\n",
        "\n",
        "    ParticipantData = []\n",
        "    ParticipantData.append(filename)\n",
        "    for x in inters.flatten():\n",
        "        ParticipantData.append(x)\n",
        "    for y in percentages.flatten():\n",
        "        ParticipantData.append(y)\n",
        "    FullSetProbabilities.append(ParticipantData)\n",
        "\n",
        "    data_file = open('temp_markov/probabilities' + filename + '.csv', 'w')\n",
        "\n",
        "    csv_writer = csv.writer(data_file)\n",
        "\n",
        "    headings = [\"DataExploration\", \"VisualExploration\", \"InsightAction\", \"Theorizing\", \"Discovering\", \"Auditing\", \"Organizing\", \"Recognizing\", \"Tracking\", \"Total\"]\n",
        "    count = 0\n",
        "    for i in percentages:\n",
        "      if count == 0:\n",
        "        header = [\"DataExploration\", \"VisualExploration\", \"InsightAction\", \"Theorizing\", \"Discovering\", \"Auditing\", \"Organizing\", \"Recognizing\", \"Tracking\", \"Total\"]\n",
        "        csv_writer.writerow(header)\n",
        "        count += 1\n",
        "      csv_writer.writerow(i)\n",
        "\n",
        "    data_file.close()\n",
        "\n",
        "print(FullSetProbabilities)\n",
        "data_file = open(csv_file, 'w')\n",
        "\n",
        "csv_writer = csv.writer(data_file)\n",
        "\n",
        "headings = [\"DataExploration\", \"VisualExploration\", \"InsightAction\", \"Theorizing\", \"Discovering\", \"Auditing\", \"Organizing\", \"Recognizing\", \"Tracking\", \"Total\"]\n",
        "count = 0\n",
        "for i in FullSetProbabilities:\n",
        "    if count == 0:\n",
        "        header = [\"FileName\", \"DataExplorationCounts\", \"VisualExplorationCounts\", \"InsightActionCounts\", \"TheorizingCounts\", \"DiscoveringCounts\", \"AuditingCounts\", \"OrganizingCounts\", \"RecognizingCounts\", \"TrackingCounts\",\n",
        "                  \"DataExploringUsual\", \"VisualExploringUsual\", \"InsightActionUsual\", \"TheorizingUsual\", \"DiscoveringUsual\", \"AuditingUsual\", \"OrganizingUsual\", \"RecognizingUsual\", \"TrackingUsual\", \"TotalUsual\",\n",
        "                  \"DataExploringUnusual\", \"VisualExploringUnusual\", \"InsightActionUnusual\", \"TheorizingUnusual\", \"DiscoveringUnusual\", \"AuditingUnusual\", \"OrganizingUnusual\", \"RecognizingUnusual\", \"TrackingUnusual\", \"TotalUnusual\"]\n",
        "        csv_writer.writerow(header)\n",
        "        count += 1\n",
        "    csv_writer.writerow(i)\n",
        "\n",
        "data_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y21MSx5SR4L8"
      },
      "source": [
        "## Run on single participant for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVr2jDyUA-v9",
        "outputId": "c30baf64-a76f-4807-9c19-609cb426cd66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arms_P1_InteractionsLogs.json\n",
            "\n",
            "\n",
            "\n",
            "[[204.]\n",
            " [144.]\n",
            " [ 49.]\n",
            " [101.]\n",
            " [ 80.]\n",
            " [ 67.]\n",
            " [ 67.]\n",
            " [ 52.]\n",
            " [114.]]\n",
            "[[152.  52.]\n",
            " [144.   0.]\n",
            " [ 34.  15.]\n",
            " [ 51.  50.]\n",
            " [ 44.  36.]\n",
            " [ 35.  32.]\n",
            " [ 58.   9.]\n",
            " [ 26.  26.]\n",
            " [ 84.  30.]]\n",
            "[[0.74509804 0.25490196]\n",
            " [1.         0.        ]\n",
            " [0.69387755 0.30612245]\n",
            " [0.5049505  0.4950495 ]\n",
            " [0.55       0.45      ]\n",
            " [0.52238806 0.47761194]\n",
            " [0.86567164 0.13432836]\n",
            " [0.5        0.5       ]\n",
            " [0.73684211 0.26315789]\n",
            " [0.71526196 0.28473804]]\n"
          ]
        }
      ],
      "source": [
        "directory = './../data/Dataset_1/User Interactions/'\n",
        "filename = 'Arms_P1_InteractionsLogs.json'\n",
        "\n",
        "print(filename + \"\\n\")\n",
        "json_to_csv(directory, filename)\n",
        "activities, state_types, state_count, transition_types, state_transitions, transition_counts = state_collecting(\"temp_markov/\"+filename+'.csv')\n",
        "\n",
        "m, labels = transition_matrix(transition_counts, transition_types, state_count, state_transitions, activities)\n",
        "print(\"\\n\")\n",
        "# for row in m: print(' '.join('{0:.3f}'.format(x) for x in row))\n",
        "# for row in labels: print(' '.join('{}'.format(x) for x in row))\n",
        "\n",
        "label_masked = mask_labels(labels)\n",
        "# for row in label_masked: print(' '.join('{}'.format(x) for x in row))\n",
        "expected2 = categorize_actions_row_average(activities, transition_counts, m)\n",
        "inters = interaction_category_counts(state_transitions)\n",
        "\n",
        "print(inters)\n",
        "print(expected2)\n",
        "percentages = expected2/inters\n",
        "percentage_Totals = (sum(expected2)/sum(inters))\n",
        "percentages.resize((10,2))\n",
        "percentages[-1] = percentage_Totals\n",
        "print(percentages)\n",
        "\n",
        "percentages = percentages.transpose()\n",
        "\n",
        "ParticipantData = []\n",
        "for x in inters.flatten():\n",
        "    ParticipantData.append(x)\n",
        "for y in percentages.flatten():\n",
        "    ParticipantData.append(y)\n",
        "\n",
        "prob_file = open('temp_markov/probabilities' + filename + '.csv', 'w')\n",
        "csv_writer = csv.writer(prob_file)\n",
        "\n",
        "header = [\"DataExplorationCounts\", \"VisualExplorationCounts\", \"InsightActionCounts\", \"TheorizingCounts\", \"DiscoveringCounts\", \"AuditingCounts\", \"OrganizingCounts\", \"RecognizingCounts\", \"TrackingCounts\",\n",
        "            \"DataExploringUsual\", \"VisualExploringUsual\", \"InsightActionUsual\", \"TheorizingUsual\", \"DiscoveringUsual\", \"AuditingUsual\", \"OrganizingUsual\", \"RecognizingUsual\", \"TrackingUsual\", \"TotalUsual\",\n",
        "            \"DataExploringUnusual\", \"VisualExploringUnusual\", \"InsightActionUnusual\", \"TheorizingUnusual\", \"DiscoveringUnusual\", \"AuditingUnusual\", \"OrganizingUnusual\", \"RecognizingUnusual\", \"TrackingUnusual\", \"TotalUnusual\"]\n",
        "csv_writer.writerow(header)\n",
        "\n",
        "csv_writer.writerow(ParticipantData)\n",
        "\n",
        "prob_file.close()\n",
        "\n",
        "data_file = open('temp_markov/MarkovValues' + filename + '.csv', 'w')\n",
        "\n",
        "csv_writer = csv.writer(data_file)\n",
        "\n",
        "count = 0\n",
        "for i in m:\n",
        "  if count == 0:\n",
        "    header = state_types.flatten()\n",
        "    csv_writer.writerow(header)\n",
        "    count += 1\n",
        "\n",
        "  csv_writer.writerow(i)\n",
        "\n",
        "data_file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yFO54-ySIl0"
      },
      "source": [
        "# Visualization Attempts (Ignore these, as they don't work)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EaqfC6SORss"
      },
      "outputs": [],
      "source": [
        "### Attempt to Visualize States ###\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.collections import PatchCollection\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "class Node():\n",
        "\n",
        "    def __init__(\n",
        "        self, center, radius, label,\n",
        "        facecolor='#2693de', edgecolor='#e6e6e6',\n",
        "        ring_facecolor='#a3a3a3', ring_edgecolor='#a3a3a3'\n",
        "        ):\n",
        "        \"\"\"\n",
        "        Initializes a Markov Chain Node(for drawing purposes)\n",
        "        Inputs:\n",
        "            - center : Node (x,y) center\n",
        "            - radius : Node radius\n",
        "            - label  : Node label\n",
        "        \"\"\"\n",
        "        self.center = center\n",
        "        self.radius = radius\n",
        "        self.label  = label\n",
        "\n",
        "        # For convinience: x, y coordinates of the center\n",
        "        self.x = center[0]\n",
        "        self.y = center[1]\n",
        "\n",
        "        # Drawing config\n",
        "        self.node_facecolor = facecolor\n",
        "        self.node_edgecolor = edgecolor\n",
        "\n",
        "        self.ring_facecolor = ring_facecolor\n",
        "        self.ring_edgecolor = ring_edgecolor\n",
        "        self.ring_width = 0.03\n",
        "\n",
        "        self.text_args = {\n",
        "            'ha': 'center',\n",
        "            'va': 'center',\n",
        "            'fontsize': 16\n",
        "        }\n",
        "\n",
        "\n",
        "    def add_circle(self, ax):\n",
        "        \"\"\"\n",
        "        Add the annotated circle for the node\n",
        "        \"\"\"\n",
        "        circle = mpatches.Circle(self.center, self.radius)\n",
        "        p = PatchCollection(\n",
        "            [circle],\n",
        "            edgecolor = self.node_edgecolor,\n",
        "            facecolor = self.node_facecolor\n",
        "        )\n",
        "        ax.add_collection(p)\n",
        "        ax.annotate(\n",
        "            self.label,\n",
        "            xy = self.center,\n",
        "            color = '#ffffff',\n",
        "            **self.text_args\n",
        "        )\n",
        "\n",
        "\n",
        "    def add_self_loop(self, ax, prob=None, direction='up'):\n",
        "        \"\"\"\n",
        "        Draws a self loop\n",
        "        \"\"\"\n",
        "        if direction == 'up':\n",
        "            start = -30\n",
        "            angle = 180\n",
        "            ring_x = self.x\n",
        "            ring_y = self.y + self.radius\n",
        "            prob_y = self.y + 1.3*self.radius\n",
        "            x_cent = ring_x - self.radius + (self.ring_width/2)\n",
        "            y_cent = ring_y - 0.15\n",
        "        else:\n",
        "            start = -210\n",
        "            angle = 0\n",
        "            ring_x = self.x\n",
        "            ring_y = self.y - self.radius\n",
        "            prob_y = self.y - 1.4*self.radius\n",
        "            x_cent = ring_x + self.radius - (self.ring_width/2)\n",
        "            y_cent = ring_y + 0.15\n",
        "\n",
        "        # Add the ring\n",
        "        ring = mpatches.Wedge(\n",
        "            (ring_x, ring_y),\n",
        "            self.radius,\n",
        "            start,\n",
        "            angle,\n",
        "            width = self.ring_width\n",
        "        )\n",
        "        # Add the triangle (arrow)\n",
        "        offset = 0.2\n",
        "        left   = [x_cent - offset, ring_y]\n",
        "        right  = [x_cent + offset, ring_y]\n",
        "        bottom = [(left[0]+right[0])/2., y_cent]\n",
        "        arrow  = plt.Polygon([left, right, bottom, left])\n",
        "\n",
        "        p = PatchCollection(\n",
        "            [ring, arrow],\n",
        "            edgecolor = self.ring_edgecolor,\n",
        "            facecolor = self.ring_facecolor\n",
        "        )\n",
        "        ax.add_collection(p)\n",
        "\n",
        "        # Probability to add?\n",
        "        if prob:\n",
        "            ax.annotate(str(prob), xy=(self.x, prob_y), color='#000000', **self.text_args)\n",
        "\n",
        "\n",
        "class MarkovChain:\n",
        "\n",
        "    def __init__(self, M, labels):\n",
        "        \"\"\"\n",
        "        Initializes a Markov Chain (for drawing purposes)\n",
        "        Inputs:\n",
        "            - M         Transition Matrix\n",
        "            - labels    State Labels\n",
        "        \"\"\"\n",
        "\n",
        "        if M.shape[0] < 2:\n",
        "            raise Exception(\"There should be at least 2 states\")\n",
        "        # if M.shape[0] > 4:\n",
        "        #     raise Exception(\"Only works with 4 states max for now\")\n",
        "        if M.shape[0] != M.shape[1]:\n",
        "            raise Exception(\"Transition matrix should be square\")\n",
        "        if M.shape[0] != len(labels):\n",
        "            raise Exception(\"There should be as many labels as states\")\n",
        "\n",
        "        self.M = M\n",
        "        self.n_states = M.shape[0]\n",
        "        self.labels = labels\n",
        "\n",
        "        # Colors\n",
        "        self.arrow_facecolor = '#a3a3a3'\n",
        "        self.arrow_edgecolor = '#a3a3a3'\n",
        "\n",
        "        self.node_facecolor = '#2693de'\n",
        "        self.node_edgecolor = '#e6e6e6'\n",
        "\n",
        "        # Drawing config\n",
        "        self.node_radius = 0.5\n",
        "        self.arrow_width = 0.03\n",
        "        self.arrow_head_width = 0.20\n",
        "        self.text_args = {\n",
        "            'ha': 'center',\n",
        "            'va': 'center',\n",
        "            'fontsize': 16\n",
        "        }\n",
        "\n",
        "        # Build the network\n",
        "        self.build_network()\n",
        "\n",
        "\n",
        "    def set_node_centers(self):\n",
        "        \"\"\"\n",
        "        Positions the node centers given the number of states\n",
        "        \"\"\"\n",
        "        # Node positions\n",
        "        self.node_centers = []\n",
        "\n",
        "        if self.n_states == 2:\n",
        "            self.figsize = (10, 4)\n",
        "            self.xlim = (-5, 5)\n",
        "            self.ylim = (-2, 2)\n",
        "            self.node_centers = [[-4,0], [4,0]]\n",
        "        elif self.n_states == 3:\n",
        "            self.figsize = (10, 6)\n",
        "            self.xlim = (-5, 5)\n",
        "            self.ylim = (-3, 3)\n",
        "            self.node_centers = [[-3,-2], [3,-2], [-3,2]]\n",
        "        elif self.n_states == 4:\n",
        "            self.figsize = (8, 8)\n",
        "            self.xlim = (-5, 5)\n",
        "            self.ylim = (-5, 5)\n",
        "            self.node_centers = [[-4,4], [4,4], [4,-4], [-4,-4]]\n",
        "        else:\n",
        "            self.figsize = (self.n_states * 2, self.n_states * 2)\n",
        "            self.xlim = (-20,20)\n",
        "            self.ylim = (-20,20)\n",
        "            self.node_centers = [[-10, 15], [0, 15], [10, 15], [-10, 5], [0, 5], [10, 5], [-10, -5], [0, -5], [10, -5], [-10, -15], [0, -15]]\n",
        "\n",
        "\n",
        "    def build_network(self):\n",
        "        \"\"\"\n",
        "        Loops through the matrix, add the nodes\n",
        "        \"\"\"\n",
        "        # Position the node centers\n",
        "        self.set_node_centers()\n",
        "\n",
        "        # Set the nodes\n",
        "        self.nodes = []\n",
        "        for i in range(self.n_states):\n",
        "            node = Node(\n",
        "                self.node_centers[i],\n",
        "                self.node_radius,\n",
        "                self.labels[i]\n",
        "            )\n",
        "            self.nodes.append(node)\n",
        "\n",
        "\n",
        "    def add_arrow(self, ax, node1, node2, prob=None):\n",
        "        \"\"\"\n",
        "        Add a directed arrow between two nodes\n",
        "        \"\"\"\n",
        "        # x,y start of the arrow\n",
        "        x_start = node1.x + np.sign(node2.x-node1.x) * node1.radius\n",
        "        y_start = node1.y + np.sign(node2.y-node1.y) * node1.radius\n",
        "\n",
        "        # arrow length\n",
        "        dx = abs(node1.x - node2.x) - 2.5* node1.radius\n",
        "        dy = abs(node1.y - node2.y) - 2.5* node1.radius\n",
        "\n",
        "        # we don't want xoffset and yoffset to both be non-nul\n",
        "        yoffset = 0.4 * self.node_radius * np.sign(node2.x-node1.x)\n",
        "        if yoffset == 0:\n",
        "            xoffset = 0.4 * self.node_radius * np.sign(node2.y-node1.y)\n",
        "        else:\n",
        "            xoffset = 0\n",
        "\n",
        "        arrow = mpatches.FancyArrow(\n",
        "            x_start + xoffset,\n",
        "            y_start + yoffset,\n",
        "            dx * np.sign(node2.x-node1.x),\n",
        "            dy * np.sign(node2.y-node1.y),\n",
        "            width = self.arrow_width,\n",
        "            head_width = self.arrow_head_width\n",
        "        )\n",
        "        p = PatchCollection(\n",
        "            [arrow],\n",
        "            edgecolor = self.arrow_edgecolor,\n",
        "            facecolor = self.arrow_facecolor\n",
        "        )\n",
        "        ax.add_collection(p)\n",
        "\n",
        "        # Probability to add?\n",
        "        x_prob = x_start + xoffset + 0.2*dx*np.sign(node2.x-node1.x)\n",
        "        y_prob = y_start + yoffset + 0.2*dy*np.sign(node2.y-node1.y)\n",
        "        if prob:\n",
        "            ax.annotate(str(prob), xy=(x_prob, y_prob), color='#000000', **self.text_args)\n",
        "\n",
        "\n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Draw the Markov Chain\n",
        "        \"\"\"\n",
        "        fig, ax = plt.subplots(figsize=self.figsize)\n",
        "\n",
        "        # Set the axis limits\n",
        "        plt.xlim(self.xlim)\n",
        "        plt.ylim(self.ylim)\n",
        "\n",
        "        # Draw the nodes\n",
        "        for node in self.nodes:\n",
        "            node.add_circle(ax)\n",
        "\n",
        "        # Add the transitions\n",
        "        for i in range(self.M.shape[0]):\n",
        "            for j in range(self.M.shape[1]):\n",
        "                # self loops\n",
        "                if i == j:\n",
        "                    # Loop direction\n",
        "                    if self.nodes[i].y >= 0:\n",
        "                        self.nodes[i].add_self_loop(ax, prob = M[i,j], direction='up')\n",
        "                    else:\n",
        "                        self.nodes[i].add_self_loop(ax, prob = M[i,j], direction='down')\n",
        "                # directed arrows\n",
        "                elif M[i,j] > 0:\n",
        "                    self.add_arrow(ax, self.nodes[i], self.nodes[j], prob = M[i,j])\n",
        "\n",
        "        plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "tlGKtTm0RvZ-",
        "outputId": "b6469e95-aa40-4858-d773-0e84e03cfe0e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-51bf46b3c793>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMarkovChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
          ]
        }
      ],
      "source": [
        "mc = MarkovChain(m, state_types)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "dU_Vy03oRxu9",
        "9yFO54-ySIl0"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
