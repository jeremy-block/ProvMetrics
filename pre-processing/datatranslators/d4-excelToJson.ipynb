{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the Excel interaction files to json for interpretation\n",
    "\n",
    "This notebook walks through the handful of steps we want to take to convert the Excel files from dataset 4 to be interpretable JSON files.\n",
    "\n",
    "Each Excel file will need to be manually modified before this can iterate over them. \n",
    " - Make sure that the actions' column is clean and a single action per line (no `expand, read` events). Split any multiple events into two rows.\n",
    " - The content of 'action_details' column is a valid JSON object. That means it should look like `'key': 'value'` pairs. \n",
    "   - **query** should follow the pattern: `{\"query_str\": \"_term_\", \"date_limits\": [\"yyyy-mm-dd\", \"yyyy-mm-dd\"], \"sort\": {\"_propName_\": {\"order\": \"desc | asc\"}}}`\n",
    "   - **query results** be an array like: `{\"results\": [\"_list_, _of_, _results_\"]}`\n",
    "   - **expand**, **read**, **collapse** Events should be: `{\"doc_id\": \"_id_\"}`\n",
    "   - Browser Search/Find functions should be type \"**find**\" and look like: `{\"query_str\": \"_term_\"}`\n",
    " - Do your best to fill in as many values in the time columns so that there is at least one column with a time for the entire session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "\n",
    "PID = 3\n",
    "input_file = '../../data/Dataset_4/User Interactions_MannuallyModified/Pandajam_p03_session 2_shareable.xlsx'  # Replace with the path to your input Excel file\n",
    "output_file = '../../data/Dataset_4/JSONInteractions/Panda_P'+str(PID)+'_interactions.json'  # Replace with the desired output JSON file path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "Import Excel data and make a Python dictionary for the rest of the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Import file and convert to json\n",
    "###\n",
    "try:\n",
    "    # Read the Excel file into a pandas DataFrame\n",
    "    df = pd.read_excel(input_file)\n",
    "    # print(df)\n",
    "\n",
    "    # Parse the JSON string into a Python dictionary\n",
    "    data_list = df.to_dict(orient='records')\n",
    "    # print(data_list)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lift Action_details up to Parent Object\n",
    "\n",
    "To help with later processing, let's take the properties colapsed in a single column of the original Excel sheet into properties we can access for each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lifted ActionDetails object properties to event level\n"
     ]
    }
   ],
   "source": [
    "# Custom function to handle non-serializable values like NaN\n",
    "def handle_non_serializable(obj):\n",
    "    if isinstance(obj, float) and math.isnan(obj):\n",
    "        return \"NaN\"\n",
    "    else:\n",
    "        raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n",
    "\n",
    "try:\n",
    "    #Clean up nested properties that are in the Action Details column\n",
    "    for obj in data_list:\n",
    "        if 'action_details' in obj:\n",
    "            # Extract the 'details' object\n",
    "            details = obj.pop('action_details')\n",
    "            #if there is no object, leave it as None\n",
    "            if isinstance(details, float):\n",
    "                obj.update({'action_details': None})\n",
    "            #if there is an object, lift it to the same level as the other properties\n",
    "            else:\n",
    "                obj.update(json.loads(details))\n",
    "\n",
    "    print(\"lifted ActionDetails object properties to event level\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designate think_aloud events\n",
    "Look for events where the action column is empty but there is a string written in the caption cell and designate this as a **think_aloud** type of event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Create a thinkAloud event type for the dataset when there is nothing written as an action and some caption written \n",
    "###\n",
    "for obj in data_list:\n",
    "    if type(obj['action']) == float and type(obj['caption'] == str):\n",
    "        obj.update({\"action\":\"think_aloud\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove any NaN value\n",
    "Finally, just to make valid JSON output, we need to handle any empty cells and set them to None (aka null in the final JSON output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Go through each event and replace NaN with Null\n",
    "###\n",
    "try:\n",
    "    def replace_nan_with_none(obj):\n",
    "        if isinstance(obj, list):\n",
    "            return [replace_nan_with_none(item) for item in obj]\n",
    "        elif isinstance(obj, dict):\n",
    "            return {key: replace_nan_with_none(value) for key, value in obj.items()}\n",
    "        elif isinstance(obj, float) and math.isnan(obj):\n",
    "            return None\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    cleaned_data = replace_nan_with_none(data_list)\n",
    "    # print(cleaned_data)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of events: 351\n",
      "Conversion successful. Output saved to ../../data/Dataset_4/JSONInteractions/Panda_P3_interactions.json\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Save to File\n",
    "###\n",
    "try:\n",
    "    print(\"Total Number of events:\",len(cleaned_data))\n",
    "    # Save the data as a JSON file\n",
    "    with open(output_file, 'w') as json_file:\n",
    "        json.dump(cleaned_data, json_file, indent=4)\n",
    "\n",
    "    print(f\"Conversion successful. Output saved to {output_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "provmetrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
